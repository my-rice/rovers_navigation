{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kph1lruSgPWp"
   },
   "outputs": [],
   "source": [
    "import rps.robotarium as robotarium\n",
    "from rps.utilities.transformations import *\n",
    "from rps.utilities.barrier_certificates import *\n",
    "from rps.utilities.misc import *\n",
    "from rps.utilities.controllers import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import scipy.stats as st\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Optimal Control Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this section is to solve a Forward Optimal Control problem to allow unicycle robots to navigate in an unstructured environment filled with obstacles. The robots should reach the goal position while avoiding the obstacles. \n",
    "\n",
    "Some hypotheses are made:\n",
    "- The robots are equipped with sensors that allow it to know its position in the environment at each time step, but this information could be subject to noise.\n",
    "- The position of the obstacles and the goal in the environment are known at each time step.\n",
    "\n",
    "The control algorithm is fully probabilistic and it works without knowing the dynamical model of the robot. The algorithm is validated through the API of the Robotarium platform by Georgia Tech, which allows to simulate the robots in the environment and to visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below some variables and functions that will be used in the following are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eszwfUCygPWs"
   },
   "outputs": [],
   "source": [
    "# Defining the input axes\n",
    "# Note: the boundaries for the control actions are the actuation constraints imposed by the physics of the robots\n",
    "\n",
    "control_space_size = 3  # Three possible inputs for each control axis\n",
    "\n",
    "U_space_1 = np.array(np.linspace((-0.5),(0.5),control_space_size)) # Control space for the first axis\n",
    "U_space_2 = np.array(np.linspace((-0.5),(0.5),control_space_size)) # Control space for the second axis\n",
    "time_step = 0.033 # Robotarium time-step (from the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7iQ2FfgPWv"
   },
   "outputs": [],
   "source": [
    "# This function performs a \"model\" step using the documented dynamics\n",
    "# Note: from the viewpoint of the controller the dynamics is not necesarily known\n",
    "def model_step(x,velocities,time_step):\n",
    "    \"\"\"This function calculates the next pose of the robots based on the current pose, the velocities and the simulation time-step.\n",
    "    Args:\n",
    "        x : The current position of the robot. 2x1 column vector .\n",
    "        velocities : The velocities of the robot along the two control axes. 2x1 column vector. \n",
    "        time_step : simulation time-step\n",
    "    Returns:\n",
    "        The next pose of the robot as a 2x1 column vector.\n",
    "    \"\"\"\n",
    "    poses = np.zeros((2,1))\n",
    "    # Update pose of the robots\n",
    "    poses[0] = x[0] + time_step*velocities[0]\n",
    "    poses[1] = x[1] + time_step*velocities[1]\n",
    "    return(poses)\n",
    "\n",
    "#Get the value of a Gaussian pf at a given point x, with mean u and covariance covar\n",
    "def my_logpdf(x, u, covar):\n",
    "    \"\"\"This function calculates the value of a multivariate Gaussian pdf at a given point x, with mean u and covariance covar\n",
    "\n",
    "    Args:\n",
    "        x : The point at which the pdf is evaluated. Nx1 column vector.\n",
    "        u : The mean vector of the Gaussian distribution. Nx1 column vector.\n",
    "        covar : The covariance matrix of the Gaussian distribution. NxN matrix.\n",
    "\n",
    "    Returns:\n",
    "        The value of the Gaussian pdf at x.\n",
    "    \"\"\"\n",
    "    k = len(x)  # dimension\n",
    "    a = np.transpose(x - u)\n",
    "    b = np.linalg.inv(covar)\n",
    "    c = x - u\n",
    "    d = np.matmul(a, b)\n",
    "    e = np.matmul(d, c)\n",
    "    numer = np.exp(-0.5 * e)\n",
    "    f = (2 * np.pi)**k\n",
    "    g = np.linalg.det(covar)\n",
    "    denom = np.sqrt(f * g)\n",
    "    pdf = numer / denom\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most general case, the Forward Optimal Control problem is defined as follows:\\\n",
    "\\\n",
    "\\\n",
    "Given $q_{0:N} := q_0 (\\textbf x_0)\\prod^N_{k=1} q^{(x)}_k(\\textbf x_k \\mid \\textbf u_k, \\, \\textbf x_{k-1}) q^{(u)}_k(\\textbf u_k \\mid \\textbf  x_{k-1})$ find the sequence of probability distributions $\\left\\{{p^{(u)}_{k\\mid k-1}}^*\\right\\}_{1:N}$ such that:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left\\{p^{(u) \\quad *}_{k|k-1}\\right\\}_{1:N} \\in \\argmin_{\\{p^{(u)}_{k|k-1}\\}_{1:N}} \\left\\{\\mathcal D_{KL}(p_{0:N} || q_{0:N}) + \\sum^N_{k=1}\\Bbb E_{\\overline p_{k-1:k}}\\left[\\Bbb E_{p^{(x)}_{k \\mid k-1}}[c_k(\\textbf{X}_k)]\\right] \\right\\}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "s.t. \\ \\ p^{(u)}_{k\\mid k-1} \\in \\mathcal D \\ \\ \\forall k \\in \\mathcal T\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$ \\text {where } \\ \\  \\overline p_{k-1 \\mid k} := p_{k-1}(\\textbf x_{k-1},\\textbf u_k) $.\\\n",
    "\\\n",
    "\\\n",
    "In our case the reference pf $q_{0:N}$ is uniform and the cost $c_k(\\textbf{X}_k)=c(\\textbf{X}_k)$ is stationary so the problem becomes:\\\n",
    "\\\n",
    "\\\n",
    "Find the sequence of probability distributions $\\left\\{{p^{(u)}_{k\\mid k-1}}^*\\right\\}_{1:N}$ such that:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left\\{p^{(u) \\quad *}_{k|k-1}\\right\\}_{1:N} \\in \\argmin_{\\{p^{(u)}_{k|k-1}\\}_{1:N}} \\left\\{ -H(p_{0:N}) + \\sum^N_{k=1}\\Bbb E_{\\overline p_{k-1:k}}\\left[\\Bbb E_{p^{(x)}_{k:k-1}}[c(\n",
    "\\textbf{X}_k)]\\right] \\right\\}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\\\ s.t. \\ \\ p^{(u)}_{k\\mid k-1} \\in \\mathcal D \\ \\ \\forall k \\in \\mathcal T\n",
    "\\end{align*}\n",
    "$$\n",
    "$ \\text {where } \\ \\  \\overline p_{k-1 \\mid k} := p_{k-1}(\\textbf x_{k-1},\\textbf u_k) \\ \\text{ and } \\ H(p_{0:N}) \\text{ is the entropy of the probability function } p_{0:N}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP0: formalize the control problem #####\n",
    "\n",
    "# Task: reverse engineer the cost function used by the robots. What is the problem formulation? \n",
    "#      Is the one below a good cost for the task? Create a heatmap to visualize the cost \n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function that is subject to minimization is:\n",
    "[]\n",
    "- The first two terms form an ellyptic paraboloid whose minimum is centered in the goal position. This term is used to push the robots towards the goal.\n",
    "- The following terms in the summation are the costs of the obstacles. Each obstacle is represented by a bivariate gaussian function centered in its position (which means that the mean of the gaussian is the position of the obstacle) with a fixed covariance matrix. The covariance matrix is diagonal which means that the two random variables are independent. This term is used to push the robots away from the obstacles.\n",
    "- The last four terms are the costs of the walls. Each wall is represented by a gaussian function centered in the wall with fixed variance. These terms are used to push the robots away from the walls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP1: fill-in the code for the function below.\n",
    "#         The function needs to return the optimal action sampled from the optimal policy.\n",
    "#         The action is used in the simulation loop #####\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "    ###\n",
    "    # Perform a control step given the fact that the target pf is uniform.\n",
    "    # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "    \n",
    "    target_pf = 1/control_space_size**2 # Uniform pf q(u_k|x_k-1)\n",
    "    time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "    for i in range(control_space_size):\n",
    "        for j in range(control_space_size):\n",
    "            # Task: what do the next three lines do?\n",
    "            \"\"\"\n",
    "            The next three lines calculate the probability function of the next state x_k given the current state x_{k-1} and the action u_k.\n",
    "            The probability function is a multivariate Gaussian distribution with mean vector x_k = x_{k-1} + u_k * time_step and covariance matrix cov = [[0.001, 0.0002], [0.0002, 0.001]].\n",
    "            \"\"\"\n",
    "            next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov) #p(x_k|u_k,x_k-1)\n",
    "            # Task: what do the next two lines do?\n",
    "            \"\"\"\n",
    "            The next two lines extract 20 samples from the probability function p(x_k|u_k,x_k-1) calculated before.\n",
    "            \"\"\"\n",
    "            N_samples = 20\n",
    "            next_sample = f.rvs(N_samples) \n",
    "\n",
    "            # Task: what do the next three lines do?\n",
    "            \"\"\"\n",
    "            The next three lines calculate an expectation of the cost function as a mean of the cost function evaluated on the 20 samples extracted before.\n",
    "            This is done to estimate the value of the cost function in the next state.\n",
    "            According to the law of large numbers, the more samples we extract, the more accurate the estimation will be.\n",
    "            \"\"\"\n",
    "            # Calcola una stima del valore atteso del costo nello stato successivo rispetto alla funzione f(x_k|x_k-1,u_k) usando 20 campioni\n",
    "            cost=0\n",
    "            #lnp = 0\n",
    "            for k in range(N_samples):\n",
    "                cost += state_cost(next_sample[k,:],goal_points,obs_points)/N_samples\n",
    "                #lnp += np.log(f.pdf(next_sample[k,:]))/N_samples\n",
    "            # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "            \"\"\"\n",
    "            Here we exploit the fact that the entropy of a pf f is defined as the expectation of the negative logarithm of f.\n",
    "            \"\"\"\n",
    "            log_DKL = np.exp(f.entropy()-cost).item() #item() function is called to cast the ndarray to a scalar which avoids a warning\n",
    "            pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "    # Task: obtain the normalizer for the policy, call it S2\n",
    "    \"\"\"\n",
    "    The normalizer for the policy is the sum of the pf calculated on each possible input.\n",
    "    \"\"\"\n",
    "    S2 = np.sum(pf)\n",
    "    # Task: obtain the normalized pf (call the variable pf)\n",
    "    \"\"\"\n",
    "    To normalize the pf, we divide it by the normalizer S2.\n",
    "    \"\"\"\n",
    "    pf = np.divide(pf,S2)\n",
    "\n",
    "    # Adesso abbiamo p(u_k|x_{k-1}) e facciamo il sampling della prossima azione di controllo\n",
    "    # This is a trick to properly sample from the multi-dimensional pf\n",
    "    flat = pf.flatten()\n",
    "    sample_index = np.random.choice(a=flat.size, p=flat) # We sample an action from the flattened pf\n",
    "    # Take this index and adjust it so it matches the original array\n",
    "    adjusted_index = np.unravel_index(sample_index, pf.shape) # This function converts the index of the flattened pf back into a tuple of two indices for the original action space\n",
    "\n",
    "    action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1)) # We extract the control actions on the two control axes and we reshape them into a 2x1 column vector\n",
    "\n",
    "    return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altertive cost functions\n",
    "def state_cost_without_borders(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "def state_cost_with_additional_term(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "    state_cost = ((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) -1/((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2 +0.1)\n",
    "    cost = 30*state_cost + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "# \n",
    "def my_cilinder(x,u):\n",
    "    r = 0.4\n",
    "    k = 1000\n",
    "    height = 100\n",
    "    \n",
    "    temp = height*(-1/(1+np.exp(-k*((x[0]-u[0])**2+(x[1]-u[1])**2-(r**2)))) + 1)\n",
    "    return temp\n",
    "    \n",
    "def state_cost_cone_for_goal_point_cilinder_for_obstacles(state,goal_points,obs_points):\n",
    "\n",
    "    value = 0.05\n",
    "    a = 0.5\n",
    "    b = 0.5\n",
    "\n",
    "    v = np.array([value, value], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        \n",
    "        gauss_sum += my_cilinder(state[:2],obs_points[:2,i])\n",
    "\n",
    "    \n",
    "    if np.abs(state[0]-goal_points[0]) < 2 or np.abs(state[1]-goal_points[1]) < 2:\n",
    "        goal_point_cost = np.sqrt((state[0]-goal_points[0])**2/(a**2) + (state[1]-goal_points[1])**2/(b**2))\n",
    "    else:\n",
    "        goal_point_cost = (state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2\n",
    "    \n",
    "    cost = 30*goal_point_cost + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/value)**2)/(value*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/value)**2)/(value*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/value)**2)/(value*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/value)**2)/(value*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "def state_cost_higher_goal_weight(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 60*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "def state_cost_bigger_border(state,goal_points,obs_points):\n",
    "    displacement = 0.25\n",
    "    dev_std_border=0.08\n",
    "    multiplier_factor=dev_std_border/0.02\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(\n",
    "                multiplier_factor* np.exp(-0.5*((state[0]-(-1.5 -displacement ))/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi))\n",
    "                + multiplier_factor* np.exp(-0.5*((state[0]-1.5 - displacement)/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi)) \n",
    "                + multiplier_factor* np.exp(-0.5*((state[1]-1.0 -displacement)/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi))\n",
    "                + multiplier_factor* np.exp(-0.5*((state[1]-(-1.0 -displacement))/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "dropwave = lambda X,Y,f,s,p,o,k,A, obstacle: A*(o + np.cos(f*np.sqrt(((X-obstacle[0])/k)**2+((Y-obstacle[1])/k)**2))/((s)*((X-obstacle[0])**2+(Y-obstacle[1])**2)+p))\n",
    "dropwave_attenuation = lambda X,Y,f,s,p,o,k,A,goal,obstacle,alpha,beta: dropwave(X,Y,f,s,p,o,k,A, obstacle) * np.exp(alpha*np.sqrt((X-goal[0])**2+(Y-goal[1])**2)) * np.exp(-beta*np.sqrt((X-obstacle[0])**2+(Y-obstacle[1])**2))\n",
    "\n",
    "def experimental(state, goal_points, obs_points, parameters=None):\n",
    "    if parameters is None:\n",
    "        f =  57.67374\n",
    "        s =  100.0001\n",
    "        p =  30.000100000000003\n",
    "        o =  0.0\n",
    "        k =  4.185\n",
    "        A =  21.035\n",
    "        alpha =  4.54734\n",
    "        beta =  5.917910000000001\n",
    "    else:\n",
    "        f = parameters['f']\n",
    "        s = parameters['s']\n",
    "        p = parameters['p']\n",
    "        o = parameters['o']\n",
    "        k = parameters['k']\n",
    "        A = parameters['A']\n",
    "        alpha = parameters['alpha']\n",
    "        beta = parameters['beta']\n",
    "    \n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar) + dropwave_attenuation(state[0],state[1],f,s,p,o,k,A,goal_points,obs_points[:2,i],alpha,beta)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "experimental_cost_generator = lambda params: lambda state, goal_points, obs_points: experimental(state, goal_points, obs_points, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_parameters = {\n",
    "    'baseline':{\n",
    "        'f': 57.67374,\n",
    "        's': 100.0001,\n",
    "        'p': 30.000100000000003,\n",
    "        'o': 0.0,\n",
    "        'k': 4.185,\n",
    "        'A': 21.035,\n",
    "        'alpha': 4.54734,\n",
    "        'beta': 5.917910000000001,\n",
    "    },\n",
    "    'test':{\n",
    "        'f': 141.087560,\n",
    "        's': 79.038100,\n",
    "        'p': 250.000000,\n",
    "        'o': 0.000000,\n",
    "        'k': 10.164000,\n",
    "        'A': 12.929000,\n",
    "        'alpha': 6.804740,\n",
    "        'beta': 10.892710,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_CONDITIONS_BASELINE = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))]\n",
    "GOAL_POINTS_BASELINE = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "OBS_POINTS_BASELINE = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "COST_FUNCTION_BASELINE = state_cost\n",
    "\n",
    "SCENARIOS = {\n",
    "    'baseline': {\n",
    "        'initial_conditions': INITIAL_CONDITIONS_BASELINE,\n",
    "        'goal_points': GOAL_POINTS_BASELINE,\n",
    "        'obs_points': OBS_POINTS_BASELINE\n",
    "    },\n",
    "    'six-robots-towards-walls': {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('1.4;0.9; 0')),\n",
    "            np.array(np.mat('0.3;0.9; 1.57')),\n",
    "            np.array(np.mat('1.2;-0.5; 0')),\n",
    "            np.array(np.mat('-0.3;0.9; 1.57')),\n",
    "            np.array(np.mat('-1.40;0.625; 3.14')),\n",
    "            np.array(np.mat('0.5;-0.9; -1.57'))],\n",
    "        'goal_points': GOAL_POINTS_BASELINE,\n",
    "        'obs_points': OBS_POINTS_BASELINE\n",
    "    },\n",
    "    'obstacles-ahead-goal': {\n",
    "        'initial_conditions': [np.array(np.mat('1.4;0.9; 0')),\n",
    "                               np.array(np.mat('0.2;0.9; 0')),\n",
    "                               np.array(np.mat('1.2;-0.8; 0')),\n",
    "                               np.array(np.mat('-1;0.9; 0')),\n",
    "                               np.array(np.mat('-1;-0.75; 0')),\n",
    "                               np.array(np.mat('-1.2;-0.15; 0')),\n",
    "                               np.array(np.mat('0.4;-0.8; 0')),\n",
    "                               np.array(np.mat('-1.2;0.4; 0'))],\n",
    "        'goal_points': np.array(np.mat('+1.3; -0.3; 0')),\n",
    "        'obs_points': np.array(np.mat('0.4 -0.8 -0.6 0.6 0.8; -0.4 0.4 -0.8 0.8 -0.8; 0 0 0 0 0'))\n",
    "    },\n",
    "    'robot-on-walls': {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('1.47; 0.2; 0')),\n",
    "            np.array(np.mat('1.47; 0.2; 1.57')),\n",
    "            np.array(np.mat('1.47; 0.2; 3.14')),\n",
    "            np.array(np.mat('1.47; 0.2; -1.57'))],\n",
    "        'goal_points': np.array(np.mat('-1.3; 0; 0')),\n",
    "        'obs_points': np.array(np.mat('0.0 0.0 0.0; -0.8 0.8 0; 0 0 0 '))\n",
    "    },\n",
    "    'three-obstacles-wall':  {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('-1.0; 0.0; 0'))\n",
    "        ],\n",
    "        'goal_points': np.array(np.mat('1.0; 0.0; 0')),\n",
    "        'obs_points': np.array(np.mat('0.0 0.0 0.0; 0.0 -0.3 0.3; 0 0 0 '))\n",
    "    }\n",
    "}\n",
    "\n",
    "selected_scenario = 'three-obstacles-wall'\n",
    "selected_cost_function = experimental_cost_generator(cost_parameters['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define goal and obstacle points\n",
    "goal_points = SCENARIOS[selected_scenario]['goal_points']\n",
    "obs_points = SCENARIOS[selected_scenario]['obs_points'] # (3 x n_obstacles) matrix. Each column represents an obstacle. Rows contain the (x,y,theta) of the obstacle.\n",
    "\n",
    "# Dopo vedremo che questi 'ostacoli' virtuali si mappano a due ostacoli fisici, uno centrato in (0, -0.8) e un altro più lungo centrato in (0, 0.5).\n",
    "\n",
    "# Define the initial states of the robots\n",
    "initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']\n",
    "\n",
    "# Define the cost function\n",
    "state_cost = selected_cost_function\n",
    "\n",
    "# Define whether to show the robotarium simulations\n",
    "SHOW_SIMULATIONS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we want to visualize the cost function. First we evaluate the function on a grid of points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid boundaries\n",
    "X_LIMITS = [-1.5, 1.5]\n",
    "Y_LIMITS = [-1, 1]\n",
    "EPSILON_LIMITS = 0 # Used to plot a little bit outside the robotarium boundaries\n",
    "X_SIZE = X_LIMITS[1]-X_LIMITS[0]+2*EPSILON_LIMITS\n",
    "Y_SIZE = Y_LIMITS[1]-Y_LIMITS[0]+2*EPSILON_LIMITS\n",
    "\n",
    "# Define the grid of points where to evaluate the cost function\n",
    "X_axis = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "Y_axis = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "\n",
    "X_grid, Y_grid = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "# Evaluate the cost function on the grid\n",
    "costs = np.array([[state_cost((x,y),goal_points,obs_points) for x in X_axis] for y in Y_axis] ) #TODO: speed up this line by vectorizing it\n",
    "costs = costs.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize the cost function with a three-dimensional plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Interpolate the cost function to plot it as a surface\n",
    "# from scipy.interpolate import griddata\n",
    "# dense_x = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "# dense_y = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "# dense_X, dense_Y = np.meshgrid(dense_x, dense_y)\n",
    "# interpolated_costs = griddata((X.flatten(),Y.flatten()), costs.flatten(), (dense_X.flatten(), dense_Y.flatten()), method='cubic').reshape(dense_X.shape)\n",
    "\n",
    "\n",
    "# Plot the cost function\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_xlabel('X [m]', labelpad=10)\n",
    "ax.set_ylabel('Y [m]', labelpad=10)\n",
    "ax.set_title('Cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "surf = ax.plot_surface(X_grid, Y_grid, costs, cmap=cm.coolwarm, linewidth=0, antialiased=False, ccount=100, rcount=100) #rcount and ccount are used to make the surface smoother\n",
    "fig.colorbar(surf, shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize the cost function as an heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_grid, Y_grid, costs, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "# Plot the level curves of the cost function\n",
    "contour = ax.contour(X_grid, Y_grid, costs, cmap='coolwarm', levels=10, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=0, vmax=600) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Scatter the obstacle points\n",
    "ax.scatter(obs_points[0,:], obs_points[1,:], marker='o', s=50, color='red', zorder=3)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax) \n",
    "\n",
    "# Create a rectangle\n",
    "rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "# Add the rectangle to the plot\n",
    "ax.add_patch(rectangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qua si vedono i due ostacoli fisici, uno centrato in (0, -0.8) e un altro più lungo centrato in (0, 0.5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the modules of the gradient of the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Calculate the gradient of the cost function\n",
    "X_grad, Y_grad = np.gradient(costs.T, X_axis, Y_axis) #We need to transpose the costs matrix because we are passing the x axis as the first argument\n",
    "# Calculate the module of the gradient\n",
    "Z_grad = np.sqrt(X_grad**2 + Y_grad**2).T #We need to transpose the result because we need to plot it\n",
    "\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Cost function gradient module', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the module of the gradient of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_grid, Y_grid, Z_grad, zorder=1, cmap='RdGy', vmin=0, vmax=200)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial conditions visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "initial_conditions = np.array(initial_conditions).squeeze()\n",
    "if initial_conditions.ndim == 1:\n",
    "    initial_conditions = initial_conditions.reshape((1,3))\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(initial_conditions[:,0],initial_conditions[:,1])\n",
    "ax.scatter(goal_points[0],goal_points[1], color='green')\n",
    "ax.scatter(obs_points[0,:], obs_points[1,:], marker='o', s=50, color='red', zorder=3)\n",
    "ax.set_xlim(X_LIMITS)\n",
    "ax.set_ylim(Y_LIMITS)\n",
    "l = 0.1\n",
    "for state_index, state in enumerate(initial_conditions):\n",
    "    ax.arrow(state[0],state[1],l*np.cos(state[2]),l*np.sin(state[2]))\n",
    "    ax.annotate(str(state_index),(state[0],state[1]))\n",
    "\n",
    "# Restore the initial_conditions variable to the original value\n",
    "initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2: Simulate (4 experiments) and visualize each robot's trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WsfTaVW4gPW0",
    "outputId": "40848e0e-6a4c-4ddc-b80e-b576acbbff2b"
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "# Instantiate Robotarium object\n",
    "N = 1 #Amount of robots per simulation\n",
    "MAX_ITERATIONS = 2500\n",
    "# Initial conditions of the robot for 4 experiments\n",
    "# initial_conditions = [\n",
    "#     np.array(np.mat('1.4;0.9; 0')),\n",
    "#     np.array(np.mat('0.2;0.9; 0')),\n",
    "#     np.array(np.mat('1.2;-0.5; 0')),\n",
    "#     np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "\n",
    "initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']\n",
    "\n",
    "N_experiment = len(initial_conditions)\n",
    "# X_si is going to be two-dimensional state history\n",
    "X_Si = [0]*N_experiment\n",
    "# D_Xi is going to be two-dimensional inputs history\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "# This first for loop creates the initial conditions\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=SHOW_SIMULATIONS, initial_conditions=np.copy(initial_conditions[I]), sim_in_real_time=False)\n",
    "\n",
    "    # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "    # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "    _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "    \n",
    "    # define x initially\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    # Plotting Parameters\n",
    "    CM = np.random.rand(N+10,3) # Random Colors\n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    # Create Goal Point Markers\n",
    "    #Text with goal identification\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    #Text with goal identification\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "\n",
    "    i = 0\n",
    "    # While the robot is away from the objective ...\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N and i < MAX_ITERATIONS ):\n",
    "\n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample, U_space_1, U_space_2, goal_points, obs_points)\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    if i >= MAX_ITERATIONS:\n",
    "        print(\"SIMULATION {} FAILED!\".format(I))\n",
    "    \n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "    r.call_at_scripts_end()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ass2XqjRgPW3"
   },
   "outputs": [],
   "source": [
    "XX = X_Si #Insieme degli stati nel sistema single-integrator (y_1, y_2) per ogni simulazione\n",
    "UU = D_Xi #Insieme delle azioni di controllo per ogni simulazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyRxll4KgPW5"
   },
   "outputs": [],
   "source": [
    "#Prepare data for plotting\n",
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i])) #X=XX ma è un array di array numpy\n",
    "    X_plot.append(np.array(XX[i])) #X_plot = XX ma è un array numpy\n",
    "X = np.concatenate(X, axis=0) #X adesso è un array numpy. La prima dimensione contiene le traiettorie di tutti gli esperimenti concatenate e la secoda indicizza lo stato\n",
    "print(X.shape)\n",
    "X = np.reshape(X, (-1, 2)) # Rimuove l'ultima dimensione inutile\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i])) #U=UU ma è un array di array numpy\n",
    "    U_plot.append(np.array(UU[i])) #U_plot=UU ma è un array di array numpy\n",
    "\n",
    "U = np.concatenate(U, axis=0) #Stessa cosa di prima per le traiettorie di ingresso\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_Si))\n",
    "[print(len(X_Si[I])) for I in range(4)]\n",
    "print(len(X_Si[I][0]))\n",
    "print(len(X_Si[I][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "PqEl3OXpgPW_",
    "outputId": "a710f7af-4b2e-486e-908b-063e24924946"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Task: plot trajectories with different colors\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.plot(trajectory[:,0],trajectory[:,1])\n",
    "\n",
    "#Add a star to the starting point of each trajectory\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.scatter(trajectory[0,0], trajectory[0,1], marker='*', s=200, color='black', zorder=3)\n",
    "\n",
    "#Add a legend to the plot\n",
    "legend = []\n",
    "for i in range(N_experiment):\n",
    "    legend = legend + ['Experiment {}'.format(i+1)]\n",
    "    plt.legend(legend)\n",
    "\n",
    "#Draw obstacles\n",
    "for i in range(len(obs_points[0])):\n",
    "    for j in range(len(obs_points[1])):\n",
    "        if (i==j):\n",
    "            square=plt.Rectangle((obs_points[0][i]-0.15,obs_points[1][j]-0.15), 0.3, 0.3, fc='red',ec=\"black\")\n",
    "            plt.gca().add_patch(square)\n",
    "\n",
    "#Draw goal point\n",
    "square = plt.Rectangle((float(goal_points[0][0])-0.15,float(goal_points[1][0])-0.15), 0.3, 0.3, fc='green',ec=\"black\") # Obiettivo da raggiungere\n",
    "plt.gca().add_patch(square)\n",
    "\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.savefig('Training_Trajectories.jpg',dpi=1000,bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In rosso si vedono i due ostacoli fisici, uno centrato in (0, -0.8) e un altro più lungo centrato in (0, 0.5).\n",
    "In verde si vede approssimativamente il goal point, che nella funzione costo è una forma quadratica centrata in (-1.4, -0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Optimal Control Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature functions visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP3: Reverse engineer the features and visualize them #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjLf-AbTgPXB"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red')\n",
    "ax.scatter(goal_points[0,:],goal_points[1,:], color='green')\n",
    "ax.set_ylim(-1,1)\n",
    "ax.set_xlim(-1.5,1.5)\n",
    "ax.set_xlabel('X [m]')\n",
    "ax.set_ylabel('Y [m]')\n",
    "ax.set_title('Feature points', fontdict={'fontsize': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XXOIr-DgPXD"
   },
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1 #16\n",
    "\n",
    "# Le feature sono 16:\n",
    "# - La prima modella il goal point\n",
    "# - Altre 15 modellano potenziali ostacoli\n",
    "\n",
    "# Da come la funzione 'feature' verrà chiamata si deduce che la posizione degli ostacoli è ignota ma il goal point è noto.\n",
    "\n",
    "# Valuta il vettore di features [h(x_k)] nello stato x_k \n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32) #vettore delle varianze\n",
    "    covar = np.diag(v) #matrice di varianze e covarianze\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar) #Modelliamo gli ostacoli come multivariate gaussiane indipendenti (cov=0) centrate nell'ostacolo ipotizzato\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) #La prima feature è relativa al raggiungimento del goal point\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Define the grid of points where to evaluate the feature function\n",
    "X_axis = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "Y_axis = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "X_grid, Y_grid = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "# Calculate the feature function on the grid\n",
    "features_array = np.array([[feature((x,y),goal_points,obs_points_f,N_feature) for x in X_axis] for y in Y_axis] ) #TODO: speed up this line by vectorizing it\n",
    "\n",
    "\n",
    "# Plot the feature functions for the obstacles\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.set_xlabel('X [m]')\n",
    "ax.set_ylabel('Y [m]')\n",
    "ax.set_title('Feature functions (obstacles)', fontdict={'fontsize': 20})\n",
    "ax.set_xlim(X_LIMITS[0],X_LIMITS[1])\n",
    "ax.set_ylim(Y_LIMITS[0],Y_LIMITS[1])\n",
    "\n",
    "ax.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red', zorder=3)\n",
    "\n",
    "\n",
    "Z = np.sum(features_array[:,:,1:], axis=-1)\n",
    "colormesh = ax.pcolormesh(X_grid, Y_grid, Z, shading='auto', zorder=1)\n",
    "ax.contour(X_grid, Y_grid, Z, cmap='coolwarm', levels=5, linewidths=2, linestyles='dashed', alpha=1, zorder=2) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Plot feature function for the goal\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.set_xlabel('X [m]')\n",
    "ax.set_ylabel('Y [m]')\n",
    "ax.set_title('Feature functions (goal)', fontdict={'fontsize': 20})\n",
    "ax.set_xlim(X_LIMITS[0],X_LIMITS[1])\n",
    "ax.set_ylim(Y_LIMITS[0],Y_LIMITS[1])\n",
    "\n",
    "ax.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "\n",
    "\n",
    "Z = features_array[:,:,0]\n",
    "colormesh = ax.pcolormesh(X_grid, Y_grid, Z, shading='auto', zorder=1)\n",
    "ax.contour(X_grid, Y_grid, Z, cmap='coolwarm', levels=5, linewidths=2, linestyles='dashed', alpha=1, zorder=2) #vmin and vmax are used to make the contour lines more visible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the inverse optimal control problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAi2q4NvgPXE"
   },
   "outputs": [],
   "source": [
    "##### WP4: using the previously defined features solve the inverse optimal control problem. \n",
    "#          Plot the estimated cost. \n",
    "#          Verify that the estimated cost allows the robot to complete the task #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7shmt6xgPXF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1 #size è la lunghezza di tutte le simulazioni concatenate. Concatenare le simulazioni genera 4 termini spuri.\n",
    "w = cp.Variable((1,N_feature)) #Variabili decisionali. Sono tante quanto il numero di features.\n",
    "constraints = [w >= 0] #Per hp del problema.\n",
    "R = np.zeros((99,1)) #??? Mai usato\n",
    "L = [] #Termini della funzione target da minimizzare (la funzione da minimizzare sum(L))\n",
    "\n",
    "f_expect = np.zeros((2,20)) #???\n",
    "feature_sampled = np.zeros((N_feature,M)) #Questo è il valore atteso a sinistra in blu (tranne la moltiplicazione per w che si può portare fuori)\n",
    "PF = np.zeros((control_space_size,control_space_size,M)) #Questa è la funzione q soprasegnato indicizzata in (u_k, k) dove k è l'indice temporale\n",
    "\n",
    "for i in range(M): #i è l'i-esimo termine della funzione target da ottimizzare (somma da 1 a M), sto fissando x hat \n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size)) #Questo è il valore atteso a destra in verde (tranne la moltiplicazione per w che si può portare fuori)\n",
    "    state = np.array(X[i,:]) #Get the state \\hat x_k-1\n",
    "\n",
    "    x0 = state.reshape(-1,1) #è equivalente alla flatten(), x0 è lo stato iniziale (x0[0],x0[1])\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf \\overline q(u)\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov) #p(x_k|\\hat x_k-1, u_k) valutata per \\hat x_k-1 e u_k fissati\n",
    "            #next_sample = f.mean #next_sample = next_state, inutile\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples) #5 campioni relativi al prossimo stato. Dimensione 5 campioni x 2 variabili di stato\n",
    "            feature_sample = np.zeros((N_feature,N_samples)) # 16 feature x 5 campioni\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature) #feature_sample è una matrice che tiene sulle colonne le valutazioni delle features sui campioni. Le colonne rorrispondono ai campioni.\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1) #la media è fatta su tutti gli elementi della riga [i,;], ovvero per ogni feature i-esima faccio la media su tutti i campioni\n",
    "            #Alla fine del ciclo features contiene la stima del valore atteso delle features per ogni possibile ingresso (j,k) con \\hat x_k-1 fissato\n",
    "            #quindi ho tutte le stime dei valori attesi a destra in verde nell'equazione. Fatta con la legge dei grandi numeri.\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy())) #Prima parte del valore atteso a destra\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf #Prima parte del valore atteso a destra per ogni valore di ingresso e u_k e stato x_k-1\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # Adesso features ha come primo indice la feature e il secondo va da 0 a 8 e indica l'ingresso di controllo\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step) # Costuiramo la pdf p(x_k|\\hat x_k-1,\\hat u_k) che serve a calcolare il valore atteso a sinistra in blu\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov) #p(x_k|\\hat x_k-1,\\hat u_k)\n",
    "    next_samples_f1 = f1.rvs(N_samples) #stessa cosa di prima, stima con legge dei grandi numeri del expectation blu a sinistra\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)  # features_sampled è la stessa cosa di features fatta sul valore atteso blu. nota che u è fissata qunidi non ho come indici j e k. Ho i come indice ed è inutile.\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    # (iii) solve the problem\n",
    "    PF2 = np.reshape(PF,(-1,M))\n",
    "    # log_sum_exp prende in ingresso il vettore colonna degli elmenti da sommare\n",
    "    l = -(w @ feature_sampled[:,i]) + cp.log_sum_exp(cp.reshape(w@features[:,:],(control_space_size**2,)) + cp.log(PF2[:,i])) #(i)\n",
    "    L.append(l) #(ii)\n",
    "\n",
    "objective = cp.Minimize(cp.sum(L)) #(iii)\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = True)\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('weights.npy',np.array(w.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY1orFxPgPXH",
    "outputId": "24a7b313-560d-4e31-d3f1-49d9a25a0543"
   },
   "outputs": [],
   "source": [
    "# Show the values: critically discuss if these weights make sense\n",
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QgxBdrNgPXI",
    "outputId": "699171d0-3d2f-4195-af1c-fdbe5032e7af"
   },
   "outputs": [],
   "source": [
    "# Check the status of the optimization problem: did the optimization go well? Si\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xs5LG7IgPXJ"
   },
   "outputs": [],
   "source": [
    "# Reformatting the original cost map (just for checking and plotting purposes)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "#goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "#obs_points = np.array(np.mat('0 0 0 0 0 0;0 0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0 0'))\n",
    "#obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost(state,goal_points,obs_points)\n",
    "\n",
    "#Coat_Map = pd.DataFrame(Cost_Map,index=list(X_axis),columns=Y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXBeF23UgPXL"
   },
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap of the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "I7poUkevgPXM",
    "outputId": "e4e9bc4c-b6a7-422e-a08b-0fa3a0652535"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Transpose the data array to rotate the heatmap\n",
    "#data_rotated = np.transpose(Cost_Map)\n",
    "\n",
    "# Task: plot the reconstructed cost\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.set_xlabel(\"x1\")\n",
    "#ax.set_ylabel(\"x2\")\n",
    "#im=ax.imshow(data_rotated, cmap=matplotlib.colormaps['viridis'], extent=[-1.5,1.5,-1,1], interpolation=None,aspect=\"auto\", origin='lower')\n",
    "#plt.colorbar(im)\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import CenteredNorm\n",
    "# Transpose the data array to rotate the heatmap\n",
    "data_rotated = np.transpose(Cost_Map) \n",
    " \n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Estimated cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_axis, Y_axis, data_rotated, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "# Plot the level curves of the cost function\n",
    "contour = ax.contour(X_axis, Y_axis, data_rotated, cmap='coolwarm', shading='linear', levels=7, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=40, vmax=100) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax)\n",
    "\n",
    "# Create a rectangle\n",
    "rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "# Add the rectangle to the plot\n",
    "ax.add_patch(rectangle)\n",
    " \n",
    "plt.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red', zorder=3)\n",
    "plt.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D plot of the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_xlabel('X [m]', labelpad=10)\n",
    "ax.set_ylabel('Y [m]', labelpad=10)\n",
    "ax.set_zlabel('Cost')\n",
    "ax.set_title('Estimated Cost Function', fontdict={'fontsize': 20})\n",
    "\n",
    "surf = ax.plot_surface(X_grid, Y_grid, data_rotated, cmap=cm.coolwarm, linewidth=0, antialiased=False, ccount=100, rcount=100) #rcount and ccount are used to make the surface smoother\n",
    "fig.colorbar(surf, shrink=0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controllare se il fattore 6 ha influito sui valori del costo!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation with the estimated cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate an interpolation of the cost function to speed up the computation of the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "X_axis_interpolation = np.linspace(X_LIMITS[0]-0.5, X_LIMITS[1]+0.5, 600)\n",
    "Y_axis_interpolation = np.linspace(Y_LIMITS[0]-0.5, Y_LIMITS[1]+0.5, 400)\n",
    "X_grid_interpolation, Y_grid_interpolation = np.meshgrid(X_axis_interpolation, Y_axis_interpolation)\n",
    "Z = np.zeros((600,400))\n",
    "for i in range(600):\n",
    "    for j in range(400):\n",
    "        Z[i,j] = state_cost_estimated(np.array([X_axis_interpolation[i],Y_axis_interpolation[j]]),goal_points,obs_points_f,weights)\n",
    "\n",
    "# interpolated_costs = griddata((X_interpolation.flatten(),Y_interpolation.flatten()), Z.flatten(), (X_interpolation.flatten(), Y_interpolation.flatten()), method='cubic').reshape(dense_X.shape)\n",
    "\n",
    "# Cost_Map_2 = np.zeros((600,400))\n",
    "# X_axis_2 = np.linspace(-3.0,3.0,600)\n",
    "# Y_axis_2 = np.linspace(-2,2,400)\n",
    "\n",
    "# for i in range(400):\n",
    "#     for j in range(600):\n",
    "#         state = np.array([X_axis_2[j],Y_axis_2[i]])\n",
    "#         Cost_Map_2[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)\n",
    "\n",
    "# interpolated_cost = interpolate.RegularGridInterpolator((X_axis_2, Y_axis_2), Cost_Map_2)\n",
    "# interpolated_cost([1.49,1.0])\n",
    "\n",
    "interpolated_cost = interpolate.LinearNDInterpolator(np.stack((X_grid_interpolation.flatten(),Y_grid_interpolation.flatten()),axis=1),Z.T.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the interpolated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the heatmap of the interpolated cost function\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Interpolated cost function', fontdict={'fontsize': 20})\n",
    "TEST = np.zeros((600,400))\n",
    "\n",
    "for i in range(600):\n",
    "    for j in range(400):\n",
    "        TEST[i,j] = interpolated_cost(X_axis_interpolation[i], Y_axis_interpolation[j])\n",
    "pcolormesh = ax.pcolormesh(X_grid_interpolation, Y_grid_interpolation, TEST.T, cmap='coolwarm',  zorder=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIo_AnGpgPXT"
   },
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "    ###\n",
    "    # Perform a control step given the fact that the target pf is uniform.\n",
    "    # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "    \n",
    "    target_pf = 1/control_space_size**2 # Uniform pf q(u_k|x_k-1)\n",
    "    time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size))\n",
    "    for i in range(control_space_size):\n",
    "        for j in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            N_samples = 20\n",
    "            next_sample = f.rvs(N_samples) \n",
    "\n",
    "            # Task: what do the next three lines do?\n",
    "            # Calcola una stima del valore atteso del costo nello stato successivo rispetto alla funzione f(x_k|x_k-1,u_k) usando 20 campioni\n",
    "            cost=0\n",
    "            for k in range(N_samples):\n",
    "                #cost += state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                cost += interpolated_cost(next_sample[k,:])/N_samples\n",
    "            log_DKL = np.exp(f.entropy()-cost).item() #item is used to convert the result to a scalar\n",
    "            pf[i,j] = log_DKL \n",
    "    # Task: obtain the normalizer for the policy, call it S2\n",
    "    S2 = np.sum(pf)\n",
    "    # Task: obtain the normalized pf (call the variable pf)\n",
    "    pf = np.divide(pf,S2)\n",
    "\n",
    "    # Adesso abbiamo p(u_k|x_{k-1}) e facciamo il sampling della prossima azione di controllo\n",
    "    # This is a trick to properly sample from the multi-dimensional pf\n",
    "    flat = pf.flatten()\n",
    "    sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "    # Take this index and adjust it so it matches the original array\n",
    "    adjusted_index = np.unravel_index(sample_index, pf.shape) #Indice dell'azione\n",
    "\n",
    "    #Formatta l'azione come vettore colonna\n",
    "    action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "    return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uLNguEgFgPXU",
    "outputId": "24679b38-d525-492f-e678-8799b8a28ff6"
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "# Instantiate Robotarium object (start the robots from different initial conditions than the 4 experiments above)\n",
    "N = 1\n",
    "\n",
    "MAX_ITERATIONS = 10000\n",
    "#initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']\n",
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n",
    "#initial_conditions= [np.array(np.mat('-1;-0.75; 0')),np.array(np.mat('0.5;-0.9; -1.57')), np.array(np.mat('-1.2; 0.4; 0'))]\n",
    "\n",
    "N_experiment = len(initial_conditions)\n",
    "# X_si is going to be two-dimensional state history\n",
    "X_Si = [0]*N_experiment\n",
    "# D_Xi is going to be two-dimensional inputs history\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "# This first for loop creates the initial conditions\n",
    "\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=SHOW_SIMULATIONS, initial_conditions=np.copy(initial_conditions[I]), sim_in_real_time=False)\n",
    "\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion()\n",
    "\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    CM = np.random.rand(N+10,3) \n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "    i = 0\n",
    "    # While the robot is away from the objective ...\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N and i < MAX_ITERATIONS ):\n",
    "\n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample, U_space_1, U_space_2, goal_points, obs_points)\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "        \n",
    "        i+=1\n",
    "      \n",
    "\n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    r.call_at_scripts_end()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2gUBs9HgPXW"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zc26PNAzgPXX"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i]))\n",
    "    X_plot.append(np.array(XX[i]))\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = np.reshape(X, (-1, 2))\n",
    "\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i]))\n",
    "    U_plot.append(np.array(UU[i]))\n",
    "\n",
    "U = np.concatenate(U, axis=0)\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Sq2vsBLMgPXY",
    "outputId": "c6e65995-63e3-47ac-fb97-7d930abc5887"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#Task: plot trajectories with different colors\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.plot(trajectory[:,0],trajectory[:,1])\n",
    "\n",
    "# Add a star to the starting point of each trajectory\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.scatter(trajectory[0,0], trajectory[0,1], marker='*', s=200, color='black')\n",
    "\n",
    "# Add a legend to the plot\n",
    "legend = []\n",
    "for i in range(N_experiment):\n",
    "    legend = legend + ['Experiment {}'.format(i+1)]\n",
    "    plt.legend(legend)\n",
    "\n",
    "\n",
    "#Draw obstacles\n",
    "for i in range(len(obs_points[0])):\n",
    "    for j in range(len(obs_points[1])):\n",
    "        if (i==j):\n",
    "            square=plt.Rectangle((obs_points[0][i]-0.15,obs_points[1][j]-0.15), 0.3, 0.3, fc='red',ec=\"black\")\n",
    "            plt.gca().add_patch(square)\n",
    "\n",
    "#Draw goal point\n",
    "square = plt.Rectangle((float(goal_points[0][0])-0.15,float(goal_points[1][0])-0.15), 0.3, 0.3, fc='green',ec=\"black\") # Obiettivo da raggiungere\n",
    "plt.gca().add_patch(square)\n",
    "\n",
    "plt.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Xgg5hhMogPXQ",
    "outputId": "b8c54575-1e46-441a-991d-9561ed668256"
   },
   "outputs": [],
   "source": [
    "# Task: plot the feature points on the robotarium grid with correspopnding weights\n",
    "%matplotlib inline\n",
    "print(weights)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "for i, w in enumerate(weights[0,1:]):\n",
    "    ax.annotate(round(w,2), (obs_points_f[0,i], obs_points_f[1,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the results you observe in the figure generated by the above cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative features to recognize walls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feature = 16+10\n",
    "# Adding new features for the walls\n",
    "def augmented_feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32) #vettore delle varianze\n",
    "    covar = np.diag(v) #matrice di varianze e covarianze\n",
    "    features = np.zeros(16)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar) #Modelliamo gli ostacoli come multivariate gaussiane indipendenti (cov=0) centrate nell'ostacolo ipotizzato\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) #La prima feature è relativa al raggiungimento del goal point\n",
    "    \n",
    "    x_walls = np.linspace(X_LIMITS[0], X_LIMITS[1], 5)\n",
    "    y_walls = np.linspace(Y_LIMITS[0], Y_LIMITS[1], 5)\n",
    "    \n",
    "    x_wall = lambda x: np.exp(-0.5*((next_state[0]-x)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "    y_wall = lambda y: np.exp(-0.5*((next_state[1]-y)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "    \n",
    "    for x in x_walls:\n",
    "        features = np.append(features,x_wall(x))\n",
    "        \n",
    "    for y in y_walls:\n",
    "        features = np.append(features,y_wall(y))\n",
    "    return features\n",
    "feature = augmented_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructed cost evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    \n",
    "    x_walls = np.linspace(X_LIMITS[0], X_LIMITS[1], 5)\n",
    "    y_walls = np.linspace(Y_LIMITS[0], Y_LIMITS[1], 5)\n",
    "    \n",
    "    x_wall = lambda x: np.exp(-0.5*((state[0]-x)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "    y_wall = lambda y: np.exp(-0.5*((state[1]-y)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "    \n",
    "    for i,x in enumerate(x_walls):\n",
    "        cost += -weights[:,16+i]*x_wall(x)\n",
    "        \n",
    "    for i,y in enumerate(y_walls):\n",
    "        cost += -weights[:,21+i]*y_wall(y)\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ddc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
