{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kph1lruSgPWp"
   },
   "outputs": [],
   "source": [
    "import rps.robotarium as robotarium\n",
    "from rps.utilities.transformations import *\n",
    "from rps.utilities.barrier_certificates import *\n",
    "from rps.utilities.misc import *\n",
    "from rps.utilities.controllers import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import scipy.stats as st\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the project is to solve a Forward Optimal Control problem and then reconstruct its cost function by means of Inverse Optimal Control.\n",
    "#### Forward Optimal Control\n",
    "The aim of the FOC is to allow unicycle robots to navigate in an unstructured environment filled with obstacles. The robots should reach the goal position while avoiding the obstacles. \n",
    "\n",
    "Some hypotheses are made:\n",
    "- The robots are equipped with sensors that allow to know their position in the environment at each time step, but this information could be subject to noise.\n",
    "- The position of the obstacles and the goal in the environment are known at each time step.\n",
    "\n",
    "The control algorithm is fully probabilistic and it works without knowing the dynamical model of the robot. \n",
    "\n",
    "#### Inverse Optimal Control\n",
    "The aim of the IOC is to reconstruct the cost function of the FOC starting from the trajectories of the robots as well as the control inputs. In this case we assume to know the position of the goal but we are not aware of the position of the obstacles.\n",
    "\n",
    "Both the algorithms are validated through the API of the Robotarium platform by Georgia Tech, which allows to simulate the robots in the environment and to visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below some variables and functions that will be used in the following are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eszwfUCygPWs"
   },
   "outputs": [],
   "source": [
    "# Defining the input axes\n",
    "# Note: the boundaries for the control actions are the actuation constraints imposed by the physics of the robots\n",
    "\n",
    "control_space_size = 3  # Three possible inputs for each control axis\n",
    "\n",
    "U_space_1 = np.array(np.linspace((-0.5),(0.5),control_space_size)) # Control space for the first axis\n",
    "U_space_2 = np.array(np.linspace((-0.5),(0.5),control_space_size)) # Control space for the second axis\n",
    "time_step = 0.033 # Robotarium time-step (from the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW7iQ2FfgPWv"
   },
   "outputs": [],
   "source": [
    "# This function performs a \"model\" step using the documented dynamics\n",
    "# Note: from the viewpoint of the controller the dynamics is not necesarily known\n",
    "def model_step(x,velocities,time_step):\n",
    "    \"\"\"This function calculates the next pose of the robots based on the current pose, the velocities and the simulation time-step.\n",
    "    Args:\n",
    "        x : The current position of the robot. 2x1 column vector .\n",
    "        velocities : The velocities of the robot along the two control axes. 2x1 column vector. \n",
    "        time_step : simulation time-step\n",
    "    Returns:\n",
    "        The next pose of the robot as a 2x1 column vector.\n",
    "    \"\"\"\n",
    "    poses = np.zeros((2,1))\n",
    "    # Update pose of the robots\n",
    "    poses[0] = x[0] + time_step*velocities[0]\n",
    "    poses[1] = x[1] + time_step*velocities[1]\n",
    "    return(poses)\n",
    "\n",
    "#Get the value of a Gaussian pf at a given point x, with mean u and covariance covar\n",
    "def my_logpdf(x, u, covar):\n",
    "    \"\"\"This function calculates the value of a multivariate Gaussian pdf at a given point x, with mean u and covariance covar\n",
    "\n",
    "    Args:\n",
    "        x : The point at which the pdf is evaluated. Nx1 column vector.\n",
    "        u : The mean vector of the Gaussian distribution. Nx1 column vector.\n",
    "        covar : The covariance matrix of the Gaussian distribution. NxN matrix.\n",
    "\n",
    "    Returns:\n",
    "        The value of the Gaussian pdf at x.\n",
    "    \"\"\"\n",
    "    k = len(x)  # dimension\n",
    "    a = np.transpose(x - u)\n",
    "    b = np.linalg.inv(covar)\n",
    "    c = x - u\n",
    "    d = np.matmul(a, b)\n",
    "    e = np.matmul(d, c)\n",
    "    numer = np.exp(-0.5 * e)\n",
    "    f = (2 * np.pi)**k\n",
    "    g = np.linalg.det(covar)\n",
    "    denom = np.sqrt(f * g)\n",
    "    pdf = numer / denom\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define goal and obstacle points\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP0 - Problem statements and cost function analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Control Problem Statement\n",
    "In the most general case, the Forward Optimal Control problem is defined as follows:\\\n",
    "\\\n",
    "\\\n",
    "Given the joint probability function $q_{0:N} := q_0 (\\mathbf x_0)\\prod^N_{k=1} q^{(x)}_k(\\mathbf x_k \\mid \\mathbf u_k, \\, \\mathbf x_{k-1}) q^{(u)}_k(\\mathbf u_k \\mid \\mathbf  x_{k-1})$ find the sequence of probability functions $\\left\\{{p^{(u)}_{k\\mid k-1}}^*\\right\\}_{1:N}$ such that:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left\\{p^{(u) \\quad *}_{k|k-1}\\right\\}_{1:N} \\in \\argmin_{\\{p^{(u)}_{k|k-1}\\}_{1:N}} \\left\\{\\mathcal D_{KL}(p_{0:N} || q_{0:N}) + \\sum^N_{k=1}\\Bbb E_{\\overline p_{k-1:k}}\\left[\\Bbb E_{p^{(x)}_{k \\mid k-1}}[c_k(\\mathbf{X}_k)]\\right] \\right\\}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "s.t. \\ \\ p^{(u)}_{k\\mid k-1} \\in \\mathcal D \\ \\ \\forall k \\in \\mathcal T\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$ \\text {where } \\ \\  \\overline p_{k-1 \\mid k} := p_{k-1}(\\mathbf x_{k-1},\\mathbf u_k) $.\\\n",
    "\\\n",
    "\\\n",
    "In our case the problem can be simplified because:\n",
    "\n",
    "- The first term in the cost functional acts as a regularzer that biases the behavior of the system towards the reference distribution $q_{0:N}$. In our case the reference pf $q_{0:N}$ is uniform so the first term becomes an entropic regularizer;\n",
    "- The cost $c_k(\\mathbf{X}_k)=c(\\mathbf{X}_k)$ is stationary.\n",
    "\n",
    "Thus the formulation of the forward control problem becomes:\\\n",
    "\\\n",
    "\\\n",
    "Find the sequence of probability distributions $\\left\\{{p^{(u)}_{k\\mid k-1}}^*\\right\\}_{1:N}$ such that:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left\\{p^{(u) \\quad *}_{k|k-1}\\right\\}_{1:N} \\in \\argmin_{\\{p^{(u)}_{k|k-1}\\}_{1:N}} \\left\\{ -H(p_{0:N}) + \\sum^N_{k=1}\\Bbb E_{\\overline p_{k-1:k}}\\left[\\Bbb E_{p^{(x)}_{k:k-1}}[c(\n",
    "\\mathbf{X}_k)]\\right] \\right\\}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\\\ s.t. \\ \\ p^{(u)}_{k\\mid k-1} \\in \\mathcal D \\ \\ \\forall k \\in \\mathcal T\n",
    "\\end{align*}\n",
    "$$\n",
    "$ \\text {where } \\ \\  \\overline p_{k-1 \\mid k} := p_{k-1}(\\mathbf x_{k-1},\\mathbf u_k) \\ \\text{ and } \\ H(p_{0:N}) \\text{ is the entropy of the probability function } p_{0:N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Control Problem Statement\n",
    "In order to define the Inverse Control Problem we define the following assumptions:\n",
    "- We suppose that there exists a sequence of pfd $\\left\\{{p^{(u)}_{k\\mid k-1}}^*\\right\\}_{1:N}$ that is feasible for the forward control problem defined above and such that the objective functional is finite;\n",
    "- We suppose that the cost-to-go is expressed as a linear combination of some features $\\mathbf{h}(\\mathbf x_k)$. In other words $\\overline c_k(\\mathbf x_k)=-\\mathbf w_k^T \\mathbf h(\\mathbf x_k)$ where $\\mathbf h(\\mathbf x_k):=[h_1(\\mathbf x_k),\\dots, h_F(\\mathbf x_k)]^T$ is the features vector and $h_i: X\\rarr \\Bbb  R$ are known functions with $i \\in \\{1,\\dots,F\\}$ and $\\mathbf w_k:=[w_{k,1},\\dots,w_{k,F}]^T$ is the weight vector;\n",
    "\n",
    "The inverse control problem (already formulated in the case of a stationary cost and uniform $q_{0:N}$) is defined as follows:\n",
    "\n",
    "Let $\\{(\\hat{\\mathbf x}_{k-1}, {\\hat {\\mathbf u}_{k}})\\}_{1:M}$ be the observed data with $\\hat{\\mathbf x}_{k-1} \\sim p^{(x)}_{k\\mid k-1}, \\hat {\\mathbf u}_{k} \\sim p^{(u)}_{k\\mid k-1}$. The maximum likelihood estimate for the cost\n",
    "\n",
    "$$ \\mathbf w^* := [w_{1}^{*T}, \\cdots, \\mathbf w_{M}^{*T}]^{T} \\in \n",
    "\\argmin \\left\\{ \\sum_{i=1}^{M}\\left(-\\Bbb E_{p(x_{k}|\\hat x_{k-1}, \\hat u_k)}\\left[w_{k}^{T} \\cdot h(x_{k})\\right]\n",
    "+ \n",
    "\\ln\\left(\\sum_{u_k} \\exp\\left(-\\Bbb E_{p(x_{k}|\\hat x_{k-1}, u_k)} \\left[\\ln(p(x_{k}|\\hat x_{k-1}, u_k))+\\mathbf w^{T} \\cdot h(x_{k})\\right]\\right)\\right)\\right) \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP0: formalize the control problem #####\n",
    "\n",
    "# Task: reverse engineer the cost function used by the robots. What is the problem formulation? \n",
    "#      Is the one below a good cost for the task? Create a heatmap to visualize the cost \n",
    "\"\"\"The task has been answered in the blocks below.\"\"\"\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf x_k = [x_k, y_k] \\in \\Bbb R^2$ be the current position of the robot, $\\mathbf x_d \\in \\Bbb R^2$ be the desired goal for the robot, $\\mathbf o_i \\in \\Bbb R^2$ be the position of the i-th obstacle, n the number of obstacles. The cost function that is subject to minimization is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    c(\\mathbf{x}_k) = 30(\\mathbf x_k - x_d)^2 + 20\\sum_{i=1}^n g_i(\\mathbf x_k) + 10\\sum_{j=1}^4 h_j(\\mathbf x_k)\n",
    "\\end{equation}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "g_i(\\mathbf{x}_k) = \\frac{1}{\\sqrt{(2\\pi)^2\\text{det}({\\mathbf {\\Sigma}}_o)}} \\exp\\left(-\\frac{1}{2}(\\mathbf x_k - \\mathbf o_i)^T \\Sigma_o^{-1} (\\mathbf x_k - \\mathbf o_i)\\right)\n",
    "$$\n",
    "is a bivariate gaussian function with mean vector $\\mu=\\mathbf o_i$ and covariance matrix $\\mathbf \\Sigma_o = \\begin{bmatrix} 0.02 & 0 \\\\ 0 & 0.02 \\end{bmatrix}$ and\n",
    "$$\n",
    "h_1(\\mathbf x_k) = \\frac{1}{(0.02) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x_k - (-1.5)}{(0.02)}\\right)^2\\right) \\\\\n",
    "h_2(\\mathbf x_k) = \\frac{1}{(0.02) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{x_k - (1.5)}{(0.02)}\\right)^2\\right) \\\\ \n",
    "h_3(\\mathbf x_k) = \\frac{1}{(0.02) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{y_k - (-1)}{(0.02)}\\right)^2\\right) \\\\ \n",
    "h_4(\\mathbf x_k) = \\frac{1}{(0.02) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{y_k - (1)}{(0.02)}\\right)^2\\right) \\\\\n",
    "$$\n",
    "are four univariate gaussian functions with variance $\\sigma^2 = 0.02$. The gaussians $h_1$ and $h_2$ are calculated with respect to the x-axis and have means $\\mu_1=-1.5$, $\\mu_2=1.5$. The gaussians $h_3$ and $h_4$ are calculated with respect to the y-axis and have means $\\mu_3=-1$, $\\mu_4=1$. \n",
    "\n",
    "Given the task to be performed, the cost function can be interpreted as follows:\n",
    "- The first term $(\\mathbf x_k - x_d)^2$ is ellyptic paraboloid whose global minimum is centered in the goal position $\\mathbf x_d$. This term is used to push the robots towards the goal.\n",
    "- Each obstacle is modeled by a bivariate gaussian function $g_i$ centered in the position of the obstacle $\\mathbf o_i$. This term has a maximum on the obstacle and is used to push the robots away from the obstacles.\n",
    "- Each wall is represented by a gaussian function $h_j$. The gaussians $h_1$ and $h_2$ are centered in the x-coordinates of the left and right walls respectively. The gaussians $h_3$ and $h_4$ are centered in the y-coordinates of the bottom and top walls respectively. These terms are used to push the robots away from the walls.\n",
    "- The weights of the cost function are chosen in order to obtain a balance between the terms.\n",
    "\n",
    "Below we provide some visualizations of the cost function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function heatmap visualization\n",
    "The code below creates an heatmap of the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid boundaries\n",
    "X_LIMITS = [-1.5, 1.5]\n",
    "Y_LIMITS = [-1, 1]\n",
    "EPSILON_LIMITS = 0 # Used to plot a little bit outside the robotarium boundaries. 0 stans for disabled.\n",
    "X_SIZE = X_LIMITS[1]-X_LIMITS[0]+2*EPSILON_LIMITS\n",
    "Y_SIZE = Y_LIMITS[1]-Y_LIMITS[0]+2*EPSILON_LIMITS\n",
    "\n",
    "# Define the grid of points where to evaluate the cost function\n",
    "X_axis = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "Y_axis = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "\n",
    "X_grid, Y_grid = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "# Evaluate the cost function on the grid\n",
    "costs = np.array([[state_cost((x,y),goal_points,obs_points) for x in X_axis] for y in Y_axis] )\n",
    "costs = costs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_grid, Y_grid, costs, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "# Plot the level curves of the cost function\n",
    "contour = ax.contour(X_grid, Y_grid, costs, cmap='coolwarm', levels=10, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=100, vmax=450) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Scatter the obstacle points\n",
    "ax.scatter(obs_points[0,:], obs_points[1,:], marker='o', s=50, color='red', zorder=3)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax) \n",
    "\n",
    "# Create a rectangle\n",
    "rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "# Add the rectangle to the plot\n",
    "ax.add_patch(rectangle);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function 3D visualization\n",
    "The code below creates a 3D visualization of the cost function. The visualization is interactive and allows to rotate the cost function in order to have a better understanding of its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Interpolate the cost function to plot it as a surface\n",
    "#from scipy.interpolate import griddata\n",
    "#dense_x = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "#dense_y = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "#dense_X, dense_Y = np.meshgrid(dense_x, dense_y)\n",
    "#interpolated_costs = griddata((X.flatten(),Y.flatten()), costs.flatten(), (dense_X.flatten(), dense_Y.flatten()), method='cubic').reshape(dense_X.shape)\n",
    "\n",
    "\n",
    "# Plot the cost function\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_xlabel('X [m]', labelpad=10)\n",
    "ax.set_ylabel('Y [m]', labelpad=10)\n",
    "ax.set_title('Cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "surf = ax.plot_surface(X_grid, Y_grid, costs, cmap=cm.coolwarm, linewidth=0, antialiased=False, ccount=100, rcount=100) #rcount and ccount are used to make the surface smoother\n",
    "fig.colorbar(surf, shrink=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function gradient module visualization\n",
    "The code below creates a heatmap visualization of the module of the gradient of the cost function. This visualization is useful to understand the behavior of the robots in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Calculate the gradient of the cost function\n",
    "X_grad, Y_grad = np.gradient(costs.T, X_axis, Y_axis) #We need to transpose the costs matrix because we are passing the x axis as the first argument\n",
    "# Calculate the module of the gradient\n",
    "Z_grad = np.sqrt(X_grad**2 + Y_grad**2).T #We need to transpose the result because we need to plot it\n",
    "\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Cost function gradient module', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the module of the gradient of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_grid, Y_grid, Z_grad, zorder=1, cmap='RdGy', vmin=0, vmax=150)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax, extend='max');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP1: fill-in the code for the function below.\n",
    "#         The function needs to return the optimal action sampled from the optimal policy.\n",
    "#         The action is used in the simulation loop #####\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "    ###\n",
    "    # Perform a control step given the fact that the target pf is uniform.\n",
    "    # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "    \n",
    "    target_pf = 1/control_space_size**2 # Uniform pf q(u_k|x_k-1)\n",
    "    time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "    for i in range(control_space_size):\n",
    "        for j in range(control_space_size):\n",
    "            # Task: what do the next three lines do?\n",
    "            \"\"\"\n",
    "            The next three lines calculate the probability function p(x_k|u_k,x_{k-1}), which is the probabilistic description of the robot dynamics.\n",
    "            The robot dynamics is assumed to be x_k = x_{k-1} + u_k * time_step, where u_k is the velocity control action.\n",
    "            Here we are emulating a Gaussian measurement noise for the robot position, hence we choose the transition probability function p(x_k|u_k,x_{k-1})\n",
    "            to be a Gaussian distribution with mean x_{k-1} + u_k * time_step and covariance matrix cov = [[0.001, 0.0002], [0.0002, 0.001]].\n",
    "            \"\"\"\n",
    "            next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step) # The mean of the probability function p(x_k|u_k,x_{k-1})\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]]) # The covariance matrix of the probability function p(x_k|u_k,x_{k-1})\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov) #f is the probability function p(x_k|u_k,x_{k-1})\n",
    "            # Task: what do the next two lines do?\n",
    "            \"\"\"\n",
    "            The next two lines extract 20 samples from the probability function p(x_k|u_k,x_k-1) calculated before.\n",
    "            \"\"\"\n",
    "            N_samples = 20\n",
    "            next_sample = f.rvs(N_samples) \n",
    "\n",
    "            # Task: what do the next three lines do?\n",
    "            \"\"\"\n",
    "            The next three lines calculate an estimation of the expectation of the cost function c(X_k) over the pf p(x_k|u_k,x_k-1).\n",
    "            The estimation is calcualated by means of Monte Carlo sampling, as a mean of the cost function evaluated on the 20 samples extracted before.\n",
    "            According to the law of large numbers, the more samples we extract, the more accurate the estimation will be.\n",
    "            The estimated expectation of the cost function is calculated because we need it to calculate the greedy approximation of the optimal policy.\n",
    "            \"\"\"\n",
    "            cost=0\n",
    "            for k in range(N_samples):\n",
    "                cost += state_cost(next_sample[k,:],goal_points,obs_points)/N_samples\n",
    "            # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "            \"\"\"\n",
    "            Here we implement the greedy sub-optimal solution for the FOC problem as we only consider the immediate cost c(X_k).\n",
    "            The expectation of the cost function is already calculated above.\n",
    "            We exploit the fact that p(x_k|u_k,x_{k-1}) is a Gaussian distribution with known mean and covariance matrix to calculate the DKL\n",
    "            analytically, without making numerical estimations. \n",
    "            More specifically we can use the entropy because it is defined as the expectation of the negative logarithm of the pf w.r.t. the pf itself.\n",
    "            \"\"\"\n",
    "            log_DKL = np.exp(f.entropy()-cost).item() # item() function is called to cast the ndarray to a scalar which avoids a warning in the code that will follow\n",
    "            pf[i,j] = log_DKL # Calculate the DKL for each possible input, get corresponding probability\n",
    "    # Task: obtain the normalizer for the policy, call it S2\n",
    "    \"\"\"\n",
    "    The normalizer for the policy is the exponential twisted kernel.\n",
    "    Here we calculate it simply as the sum of the pf calculated on each possible input.\n",
    "    \"\"\"\n",
    "    S2 = np.sum(pf)\n",
    "    # Task: obtain the normalized pf (call the variable pf)\n",
    "    \"\"\"\n",
    "    To normalize the pf, we divide it by the normalizer S2.\n",
    "    \"\"\"\n",
    "    pf = np.divide(pf,S2)\n",
    "\n",
    "    \"\"\"Now that we calculated the greedy policy we can sample the next control action from it.\"\"\"\n",
    "    # This is a trick to properly sample from the multi-dimensional pf\n",
    "    flat = pf.flatten()\n",
    "    sample_index = np.random.choice(a=flat.size, p=flat) # We sample an action from the flattened pf\n",
    "    # Take this index and adjust it so it matches the original array\n",
    "    adjusted_index = np.unravel_index(sample_index, pf.shape) # This function converts the index of the flattened pf back into a tuple of two indices for the original action space\n",
    "\n",
    "    action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1)) # We extract the control actions on the two control axes and we reshape them into a 2x1 column vector\n",
    "\n",
    "    return(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the solution of the FOC problem\n",
    "The optimal solution to the FOC problem we defined before (with entropy regularization and a stationary cost) is given by the following equation:\n",
    "\n",
    "$${p_{k|k-1}^{(u)}}^* = \\frac{\\exp\\left(-\\mathbb{E}_{p_{k|k-1}^{(x)}}\\left[\\ln(p_{k|k-1}^{(x)}) + \\overline{c}(\\mathbf{X}_k)\\right]\\right)}{\\sum_{u_k} \\exp\\left(-\\mathbb{E}_{p_{k|k-1}^{(x)}}\\left[\\ln(p_{k|k-1}^{(x)}) + \\overline{c}(\\mathbf{X}_k)\\right]\\right)}$$\n",
    "where $\\overline{c}(\\mathbf{X}_k) = c(\\mathbf X_k) - \\hat c(\\mathbf X_k)$ and $\\hat c_k(\\mathbf X_k)$ calculated with the recursive formula:\n",
    "\n",
    "$$\\hat c(\\mathbf X_k) = \\ln \\left(\\sum_{\\mathbf u_k}\\left(-\\Bbb E_{p_{k|k+1}^{(x)}}\\left[\\ln(p_{k|k+1}^{(x)})+\\overline c(\\mathbf X_{k+1})\\right]\\right)\\right),\\\\\n",
    "\\Bbb E_{p_{N+1|N}^{(x)}}\\left[\\ln(p_{N+1|N}^{(x)})+\\overline c(\\mathbf X_{N+1})\\right] = 0$$\n",
    "\n",
    "In order to reduce the computational complexity in the code above we implemented a sub-optimal solution to the FOC problem by using the immediate cost instead of the cost-to-go:\n",
    "$${p_{k|k-1}^{(u)}} = \\frac{\\exp\\left(-\\mathbb{E}_{p_{k|k-1}^{(x)}}\\left[\\ln(p_{k|k-1}^{(x)}) + {c}(\\mathbf{X}_k)\\right]\\right)}{\\sum_{u_k} \\exp\\left(-\\mathbb{E}_{p_{k|k-1}^{(x)}}\\left[\\ln(p_{k|k-1}^{(x)}) + {c}(\\mathbf{X}_k)\\right]\\right)}$$\n",
    "\n",
    "This means that in order to evaluate the control action at each time step the agent only looks at a single step ahead. This could lead to the agent getting stuck in a local minimum of the cost function.\n",
    "\n",
    "### Comparison with the methods seen in class\n",
    "The general formulation of the FOC problem is a generalization of the so-called \"fully probabilistic control\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WP2: Simulate (4 experiments) and visualize each robot's trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WsfTaVW4gPW0",
    "outputId": "40848e0e-6a4c-4ddc-b80e-b576acbbff2b"
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "# Instantiate Robotarium object\n",
    "N = 1 # Amount of robots per simulation\n",
    "MAX_ITERATIONS = 5000 # Maximum number of iterations per experiment beceause the robot is not guaranteed to arrive at the goal\n",
    "# Initial conditions of the robot for 4 experiments\n",
    "initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))] #Initial pose of the robots\n",
    "\n",
    "\n",
    "N_experiment = 4\n",
    "# X_si is going to be two-dimensional state history\n",
    "X_Si = [0]*N_experiment\n",
    "# D_Xi is going to be two-dimensional inputs history\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "# This first for loop creates the initial conditions\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "    #we use mp.copy to avoid that the initial conditions are modified by the simulation\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=initial_conditions[I], sim_in_real_time=False)\n",
    "\n",
    "    # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "    # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "    _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "    \n",
    "    # define x initially\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    # Plotting Parameters\n",
    "    CM = np.random.rand(N+10,3) # Random Colors\n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    # Create Goal Point Markers\n",
    "    #Text with goal identification\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    #Text with goal identification\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    #Plot text for caption\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "\n",
    "    i = 0\n",
    "    # While the robot is away from the objective ...\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N and i < MAX_ITERATIONS ):\n",
    "\n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        \"\"\"Here we simply call the function Control_step defined above to calculate the action sampled from the solution to the FOC problem.\"\"\"\n",
    "        dxi = Control_step(x_sample, U_space_1, U_space_2, goal_points, obs_points)\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    \"\"\"Here we print an error message if the robot does not reach the goal within the maximum number of iterations.\"\"\"\n",
    "    if i >= MAX_ITERATIONS:\n",
    "        print(\"SIMULATION {} FAILED!\".format(I))\n",
    "    \n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "    r.call_at_scripts_end()\n",
    "    plt.close() # Added to avoid a bug later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ass2XqjRgPW3"
   },
   "outputs": [],
   "source": [
    "XX = X_Si #Insieme degli stati nel sistema single-integrator (y_1, y_2) per ogni simulazione\n",
    "UU = D_Xi #Insieme delle azioni di controllo per ogni simulazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyRxll4KgPW5"
   },
   "outputs": [],
   "source": [
    "#Prepare data for plotting\n",
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i])) #X=XX ma è un array di array numpy\n",
    "    X_plot.append(np.array(XX[i])) #X_plot = XX ma è un array numpy\n",
    "X = np.concatenate(X, axis=0) #X adesso è un array numpy. La prima dimensione contiene le traiettorie di tutti gli esperimenti concatenate e la secoda indicizza lo stato\n",
    "X = np.reshape(X, (-1, 2)) # Rimuove l'ultima dimensione inutile\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i])) #U=UU ma è un array di array numpy\n",
    "    U_plot.append(np.array(UU[i])) #U_plot=UU ma è un array di array numpy\n",
    "\n",
    "U = np.concatenate(U, axis=0) #Stessa cosa di prima per le traiettorie di ingresso\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "PqEl3OXpgPW_",
    "outputId": "a710f7af-4b2e-486e-908b-063e24924946"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Task: plot trajectories with different colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.plot(trajectory[:,0],trajectory[:,1])\n",
    "\n",
    "#Add a star to the starting point of each trajectory\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.scatter(trajectory[0,0], trajectory[0,1], marker='*', s=200, color='black', zorder=3)\n",
    "\n",
    "#Add a legend to the plot\n",
    "legend = []\n",
    "for i in range(N_experiment):\n",
    "    legend = legend + ['Experiment {}'.format(i+1)]\n",
    "    plt.legend(legend)\n",
    "\n",
    "#Draw obstacles\n",
    "square1 = plt.Rectangle((-1.6,-1), 0.4, 0.4, fc='green',ec=\"black\")\n",
    "square3 = plt.Rectangle((-0.2,-1), 0.4, 0.4, fc='red',ec=\"black\")\n",
    "square2 = plt.Rectangle((-0.2,0), 0.4, 0.8, fc='red',ec=\"black\")\n",
    "plt.gca().add_patch(square2)\n",
    "plt.gca().add_patch(square1)\n",
    "plt.gca().add_patch(square3)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.savefig('Training_Trajectories.jpg',dpi=1000,bbox_inches ='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In rosso si vedono i due ostacoli fisici, uno centrato in (0, -0.8) e un altro più lungo centrato in (0, 0.5).\n",
    "In verde si vede approssimativamente il goal point, che nella funzione costo è una forma quadratica centrata in (-1.4, -0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature functions visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### WP3: Reverse engineer the features and visualize them #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjLf-AbTgPXB"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Redefining the feature points on the robotarium grid\n",
    "obs_points_f = np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red')\n",
    "ax.scatter(goal_points[0,:],goal_points[1,:], color='green')\n",
    "ax.set_ylim(-1,1)\n",
    "ax.set_xlim(-1.5,1.5)\n",
    "ax.set_xlabel('X [m]')\n",
    "ax.set_ylabel('Y [m]')\n",
    "ax.set_title('Feature points', fontdict={'fontsize': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XXOIr-DgPXD"
   },
   "outputs": [],
   "source": [
    "# Task: reverse engineer the features and critically discuss them\n",
    "\n",
    "N_feature = np.size(obs_points_f,axis=1)+1 #16\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "There are 16 features:\n",
    "- The first one models the goal point.\n",
    "- Another 15 model potential obstacles.\n",
    "\n",
    "From what the 'feature' function will be called we infer that the location of the obstacles is unknown but the goal point is known.\n",
    "\"\"\"\n",
    "\n",
    "# Valuta il vettore di features [h(x_k)] nello stato x_k \n",
    "def feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32) #vettore delle varianze\n",
    "    covar = np.diag(v) #matrice di varianze e covarianze\n",
    "    features = np.zeros(N_feature)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar) #Modelliamo gli ostacoli come multivariate gaussiane indipendenti (cov=0) centrate nell'ostacolo ipotizzato\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) #La prima feature è relativa al raggiungimento del goal point\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Define the grid of points where to evaluate the feature function\n",
    "X_axis = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "Y_axis = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "X_grid, Y_grid = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "# Calculate the feature function on the grid\n",
    "features_array = np.array([[feature((x,y),goal_points,obs_points_f,N_feature) for x in X_axis] for y in Y_axis] ) #TODO: speed up this line by vectorizing it\n",
    "\n",
    "\n",
    "# Plot the feature functions for the obstacles\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.set_xlabel('X [m]')\n",
    "ax.set_ylabel('Y [m]')\n",
    "ax.set_title('Feature functions (obstacles)', fontdict={'fontsize': 20})\n",
    "ax.set_xlim(X_LIMITS[0],X_LIMITS[1])\n",
    "ax.set_ylim(Y_LIMITS[0],Y_LIMITS[1])\n",
    "\n",
    "ax.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red', zorder=3)\n",
    "\n",
    "\n",
    "Z = np.sum(features_array[:,:,1:], axis=-1)\n",
    "colormesh = ax.pcolormesh(X_grid, Y_grid, Z, shading='auto', zorder=1)\n",
    "ax.contour(X_grid, Y_grid, Z, cmap='coolwarm', levels=5, linewidths=2, linestyles='dashed', alpha=1, zorder=2) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Plot feature function for the goal\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.set_xlabel('X [m]')\n",
    "ax.set_ylabel('Y [m]')\n",
    "ax.set_title('Feature functions (goal)', fontdict={'fontsize': 20})\n",
    "ax.set_xlim(X_LIMITS[0],X_LIMITS[1])\n",
    "ax.set_ylim(Y_LIMITS[0],Y_LIMITS[1])\n",
    "\n",
    "ax.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "\n",
    "\n",
    "Z = features_array[:,:,0]\n",
    "colormesh = ax.pcolormesh(X_grid, Y_grid, Z, shading='auto', zorder=1)\n",
    "ax.contour(X_grid, Y_grid, Z, cmap='coolwarm', levels=5, linewidths=2, linestyles='dashed', alpha=1, zorder=2) #vmin and vmax are used to make the contour lines more visible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAi2q4NvgPXE"
   },
   "outputs": [],
   "source": [
    "##### WP4: using the previously defined features solve the inverse optimal control problem. \n",
    "#          Plot the estimated cost. \n",
    "#          Verify that the estimated cost allows the robot to complete the task #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7shmt6xgPXF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "Solving the convex optimisation problem to learn the cost.\n",
    "'''\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "M = np.size(X,axis=0) - 1 #size è la lunghezza di tutte le simulazioni concatenate. Concatenare le simulazioni genera 4 termini spuri.\n",
    "w = cp.Variable((1,N_feature)) #Variabili decisionali. Sono tante quanto il numero di features.\n",
    "constraints = [w >= 0] #Per hp del problema.\n",
    "R = np.zeros((99,1)) #??? Mai usato\n",
    "L = [] #Termini della funzione target da minimizzare (la funzione da minimizzare sum(L))\n",
    "\n",
    "f_expect = np.zeros((2,20)) #???\n",
    "feature_sampled = np.zeros((N_feature,M)) #Questo è il valore atteso a sinistra in blu (tranne la moltiplicazione per w che si può portare fuori)\n",
    "PF = np.zeros((control_space_size,control_space_size,M)) #Questa è la funzione q soprasegnato indicizzata in (u_k, k) dove k è l'indice temporale\n",
    "\n",
    "for i in range(M): #i è l'i-esimo termine della funzione target da ottimizzare (somma da 1 a M), sto fissando x hat \n",
    "\n",
    "    #############################################################################################################################\n",
    "    features = np.zeros((N_feature,control_space_size,control_space_size)) #Questo è il valore atteso a destra in verde (tranne la moltiplicazione per w che si può portare fuori)\n",
    "    state = np.array(X[i,:]) #Get the state \\hat x_k-1\n",
    "\n",
    "    x0 = state.reshape(-1,1) #è equivalente alla flatten(), x0 è lo stato iniziale (x0[0],x0[1])\n",
    "    time_step = 0.033\n",
    "\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf \\overline q(u)\n",
    "\n",
    "    for j in range(control_space_size):\n",
    "        for k in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov) #p(x_k|\\hat x_k-1, u_k) valutata per \\hat x_k-1 e u_k fissati\n",
    "            #next_sample = f.mean #next_sample = next_state, inutile\n",
    "\n",
    "            N_samples = 5\n",
    "            next_samples = f.rvs(N_samples) #5 campioni relativi al prossimo stato. Dimensione 5 campioni x 2 variabili di stato\n",
    "            feature_sample = np.zeros((N_feature,N_samples)) # 16 feature x 5 campioni\n",
    "\n",
    "            for m in range(N_samples):\n",
    "                feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature) #feature_sample è una matrice che tiene sulle colonne le valutazioni delle features sui campioni. Le colonne rorrispondono ai campioni.\n",
    "\n",
    "            features[:,j,k] = np.mean(feature_sample,axis=1) #la media è fatta su tutti gli elementi della riga [i,;], ovvero per ogni feature i-esima faccio la media su tutti i campioni\n",
    "            #Alla fine del ciclo features contiene la stima del valore atteso delle features per ogni possibile ingresso (j,k) con \\hat x_k-1 fissato\n",
    "            #quindi ho tutte le stime dei valori attesi a destra in verde nell'equazione. Fatta con la legge dei grandi numeri.\n",
    "            #Calculate the DKL for each possible input, get corresponding probability\n",
    "            log_DKL = np.exp(-(-f.entropy())) #Prima parte del valore atteso a destra\n",
    "            pf[j,k] = log_DKL\n",
    "    PF[:,:,i] = pf #Prima parte del valore atteso a destra per ogni valore di ingresso e u_k e stato x_k-1\n",
    "\n",
    "    features = np.reshape(features,(N_feature,control_space_size**2)) # Adesso features ha come primo indice la feature e il secondo va da 0 a 8 e indica l'ingresso di controllo\n",
    "\n",
    "    f_sampled = model_step(state,U[i+1,:],time_step) # Costuiramo la pdf p(x_k|\\hat x_k-1,\\hat u_k) che serve a calcolare il valore atteso a sinistra in blu\n",
    "    cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "    f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov) #p(x_k|\\hat x_k-1,\\hat u_k)\n",
    "    next_samples_f1 = f1.rvs(N_samples) #stessa cosa di prima, stima con legge dei grandi numeri del expectation blu a sinistra\n",
    "    feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "    for n in range(N_samples):\n",
    "        feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "    feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)  # features_sampled è la stessa cosa di features fatta sul valore atteso blu. nota che u è fissata qunidi non ho come indici j e k. Ho i come indice ed è inutile.\n",
    "\n",
    "    # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "    # (i) prepare each individual term of the summation, say l;\n",
    "    # (ii) sum all the elements to define the cost function\n",
    "    # (iii) solve the problem\n",
    "    PF2 = np.reshape(PF,(-1,M))\n",
    "    # log_sum_exp prende in ingresso il vettore colonna degli elmenti da sommare\n",
    "    l = -(w @ feature_sampled[:,i]) + cp.log_sum_exp(cp.reshape(w@features[:,:],(control_space_size**2,)) + cp.log(PF2[:,i])) #(i)\n",
    "    L.append(l) #(ii)\n",
    "\n",
    "objective = cp.Minimize(cp.sum(L)) #(iii)\n",
    "\n",
    "prob = cp.Problem(objective)\n",
    "\n",
    "result = prob.solve(verbose = True)\n",
    "\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY1orFxPgPXH",
    "outputId": "24a7b313-560d-4e31-d3f1-49d9a25a0543"
   },
   "outputs": [],
   "source": [
    "# Show the values: critically discuss if these weights make sense\n",
    "weights = w.value\n",
    "\n",
    "print('weights:',weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QgxBdrNgPXI",
    "outputId": "699171d0-3d2f-4195-af1c-fdbe5032e7af"
   },
   "outputs": [],
   "source": [
    "# Check the status of the optimization problem: did the optimization go well? Si\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xs5LG7IgPXJ"
   },
   "outputs": [],
   "source": [
    "# Reformatting the original cost map (just for checking and plotting purposes)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "\n",
    "goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "#obs_points = np.array(np.mat('0 0 0 0 0 0;0 0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0 0'))\n",
    "obs_points = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost(state,goal_points,obs_points)\n",
    "\n",
    "# we delete this row because we understand that it is not used\n",
    "#Coat_Map = pd.DataFrame(Cost_Map,index=list(X_axis),columns=Y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXBeF23UgPXL"
   },
   "outputs": [],
   "source": [
    "# Computing the reconstructed cost map\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "#goal_points = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "\n",
    "Cost_Map = np.zeros((300,200))\n",
    "X_axis = np.linspace(-1.5,1.5,300)\n",
    "Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "for i in range(200):\n",
    "    for j in range(300):\n",
    "\n",
    "        state = np.array ([X_axis[j],Y_axis[i]])\n",
    "        Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap of the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "I7poUkevgPXM",
    "outputId": "e4e9bc4c-b6a7-422e-a08b-0fa3a0652535"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import CenteredNorm\n",
    "# Transpose the data array to rotate the heatmap\n",
    "data_rotated = np.transpose(Cost_Map) \n",
    " \n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Estimated cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_axis, Y_axis, data_rotated, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "# Plot the level curves of the cost function\n",
    "contour = ax.contour(X_axis, Y_axis, data_rotated, cmap='coolwarm', shading='linear', levels=7, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=40, vmax=100) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax)\n",
    "\n",
    "# Create a rectangle\n",
    "rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "# Add the rectangle to the plot\n",
    "ax.add_patch(rectangle)\n",
    " \n",
    "plt.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red', zorder=3)\n",
    "plt.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D plot of the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_xlabel('X [m]', labelpad=10)\n",
    "ax.set_ylabel('Y [m]', labelpad=10)\n",
    "ax.set_zlabel('Cost')\n",
    "ax.set_title('Estimated Cost Function', fontdict={'fontsize': 20})\n",
    "\n",
    "surf = ax.plot_surface(X_grid, Y_grid, data_rotated, cmap=cm.coolwarm, linewidth=0, antialiased=False, ccount=100, rcount=100) #rcount and ccount are used to make the surface smoother\n",
    "fig.colorbar(surf, shrink=0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation with the estimated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: delete interpolated cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate an interpolation of the cost function to speed up the computation of the policy ---- da togliere prima  di consegnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "X_axis_interpolation = np.linspace(X_LIMITS[0]-0.5, X_LIMITS[1]+0.5, 600)\n",
    "Y_axis_interpolation = np.linspace(Y_LIMITS[0]-0.5, Y_LIMITS[1]+0.5, 400)\n",
    "X_grid_interpolation, Y_grid_interpolation = np.meshgrid(X_axis_interpolation, Y_axis_interpolation)\n",
    "Z = np.zeros((600,400))\n",
    "for i in range(600):\n",
    "    for j in range(400):\n",
    "        Z[i,j] = state_cost_estimated(np.array([X_axis_interpolation[i],Y_axis_interpolation[j]]),goal_points,obs_points_f,weights)\n",
    "\n",
    "# interpolated_costs = griddata((X_interpolation.flatten(),Y_interpolation.flatten()), Z.flatten(), (X_interpolation.flatten(), Y_interpolation.flatten()), method='cubic').reshape(dense_X.shape)\n",
    "\n",
    "# Cost_Map_2 = np.zeros((600,400))\n",
    "# X_axis_2 = np.linspace(-3.0,3.0,600)\n",
    "# Y_axis_2 = np.linspace(-2,2,400)\n",
    "\n",
    "# for i in range(400):\n",
    "#     for j in range(600):\n",
    "#         state = np.array([X_axis_2[j],Y_axis_2[i]])\n",
    "#         Cost_Map_2[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)\n",
    "\n",
    "# interpolated_cost = interpolate.RegularGridInterpolator((X_axis_2, Y_axis_2), Cost_Map_2)\n",
    "# interpolated_cost([1.49,1.0])\n",
    "\n",
    "interpolated_cost = interpolate.LinearNDInterpolator(np.stack((X_grid_interpolation.flatten(),Y_grid_interpolation.flatten()),axis=1),Z.T.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the interpolated cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the heatmap of the interpolated cost function\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Interpolated cost function', fontdict={'fontsize': 20})\n",
    "TEST = np.zeros((600,400))\n",
    "\n",
    "for i in range(600):\n",
    "    for j in range(400):\n",
    "        TEST[i,j] = interpolated_cost(X_axis_interpolation[i], Y_axis_interpolation[j])\n",
    "pcolormesh = ax.pcolormesh(X_grid_interpolation, Y_grid_interpolation, TEST.T, cmap='coolwarm',  zorder=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIo_AnGpgPXT"
   },
   "outputs": [],
   "source": [
    "#Task: re-define the function Control_step so that it now uses the estimated cost\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points):\n",
    "    ###\n",
    "    # Perform a control step given the fact that the target pf is uniform.\n",
    "    # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "    \n",
    "    target_pf = 1/control_space_size**2 # Uniform pf q(u_k|x_k-1)\n",
    "    time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size))\n",
    "    for i in range(control_space_size):\n",
    "        for j in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            N_samples = 20\n",
    "            next_sample = f.rvs(N_samples) \n",
    "\n",
    "            # Task: what do the next three lines do?\n",
    "            # Calcola una stima del valore atteso del costo nello stato successivo rispetto alla funzione f(x_k|x_k-1,u_k) usando 20 campioni\n",
    "            cost=0\n",
    "            for k in range(N_samples):\n",
    "                #cost += state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                cost += interpolated_cost(next_sample[k,:])/N_samples\n",
    "            log_DKL = np.exp(f.entropy()-cost).item() #item is used to convert the result to a scalar\n",
    "            pf[i,j] = log_DKL \n",
    "    # Task: obtain the normalizer for the policy, call it S2\n",
    "    S2 = np.sum(pf)\n",
    "    # Task: obtain the normalized pf (call the variable pf)\n",
    "    pf = np.divide(pf,S2)\n",
    "\n",
    "    # Adesso abbiamo p(u_k|x_{k-1}) e facciamo il sampling della prossima azione di controllo\n",
    "    # This is a trick to properly sample from the multi-dimensional pf\n",
    "    flat = pf.flatten()\n",
    "    sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "    # Take this index and adjust it so it matches the original array\n",
    "    adjusted_index = np.unravel_index(sample_index, pf.shape) #Indice dell'azione\n",
    "\n",
    "    #Formatta l'azione come vettore colonna\n",
    "    action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "    return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uLNguEgFgPXU",
    "outputId": "24679b38-d525-492f-e678-8799b8a28ff6"
   },
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "# Instantiate Robotarium object (start the robots from different initial conditions than the 4 experiments above)\n",
    "N = 1\n",
    "\n",
    "MAX_ITERATIONS = 5000\n",
    "initial_conditions = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n",
    "N_experiment = 3\n",
    "# X_si is going to be two-dimensional state history\n",
    "X_Si = [0]*N_experiment\n",
    "# D_Xi is going to be two-dimensional inputs history\n",
    "D_Xi = [0]*N_experiment\n",
    "\n",
    "# This first for loop creates the initial conditions\n",
    "\n",
    "for I in range(N_experiment):\n",
    "\n",
    "    X_si = []\n",
    "    D_xi = []\n",
    "\n",
    "    r = robotarium.Robotarium(number_of_robots=N, show_figure=True, initial_conditions=np.copy(initial_conditions[I]), sim_in_real_time=False)\n",
    "\n",
    "    si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion()\n",
    "\n",
    "    x = r.get_poses()\n",
    "    x_si = uni_to_si_states(x)\n",
    "\n",
    "    CM = np.random.rand(N+10,3) \n",
    "    goal_marker_size_m = 0.15\n",
    "    obs_marker_size_m = 0.15\n",
    "    marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "    marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "    font_size = determine_font_size(r,0.1)\n",
    "    line_width = 5\n",
    "\n",
    "    goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "    goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "    goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(goal_points.shape[1])]\n",
    "\n",
    "    obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "    obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "    obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "    for ii in range(obs_points.shape[1])]\n",
    "\n",
    "    r.step()\n",
    "    i = 0\n",
    "    # While the robot is away from the objective ...\n",
    "    while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N and i < MAX_ITERATIONS ):\n",
    "\n",
    "        # Get poses of agents\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        #Add to the dataset\n",
    "        X_si.append(x_si)\n",
    "\n",
    "        # The lines below define the pdf of the robot \n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "        x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "        # This is about plotting\n",
    "        for j in range(goal_points.shape[1]):\n",
    "            goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "        for j in range(obs_points.shape[1]):\n",
    "            obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "        # Task: compute the action from the policy. Call the variable dxi: \n",
    "        # this is the action sampled from the optimal solution to the control problem\n",
    "        dxi = Control_step(x_sample, U_space_1, U_space_2, goal_points, obs_points)\n",
    "        D_xi.append(dxi)\n",
    "\n",
    "        # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "        dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "        # Set the velocities inputs\n",
    "        r.set_velocities(np.arange(N), dxu)\n",
    "        # Iterate the simulation\n",
    "        r.step()\n",
    "        \n",
    "        i+=1\n",
    "      \n",
    "\n",
    "    D_Xi[I] = D_xi\n",
    "    X_Si[I] = X_si\n",
    "\n",
    "    r.call_at_scripts_end()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2gUBs9HgPXW"
   },
   "outputs": [],
   "source": [
    "XX = X_Si\n",
    "UU = D_Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zc26PNAzgPXX"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i]))\n",
    "    X_plot.append(np.array(XX[i]))\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = np.reshape(X, (-1, 2))\n",
    "\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i]))\n",
    "    U_plot.append(np.array(UU[i]))\n",
    "\n",
    "U = np.concatenate(U, axis=0)\n",
    "U = np.reshape(U, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Sq2vsBLMgPXY",
    "outputId": "c6e65995-63e3-47ac-fb97-7d930abc5887"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#Task: plot trajectories with different colors\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.plot(trajectory[:,0],trajectory[:,1])\n",
    "\n",
    "# Add a star to the starting point of each trajectory\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.scatter(trajectory[0,0], trajectory[0,1], marker='*', s=200, color='black')\n",
    "\n",
    "# Add a legend to the plot\n",
    "legend = []\n",
    "for i in range(N_experiment):\n",
    "    legend = legend + ['Experiment {}'.format(i+1)]\n",
    "    plt.legend(legend)\n",
    "\n",
    "\n",
    "#Draw goal point\n",
    "square = plt.Rectangle((float(goal_points[0][0])-0.15,float(goal_points[1][0])-0.15), 0.3, 0.3, fc='green',ec=\"black\") # Obiettivo da raggiungere\n",
    "plt.gca().add_patch(square)\n",
    "\n",
    "plt.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "\n",
    "#Draw obstacles\n",
    "square1 = plt.Rectangle((-1.6,-1), 0.4, 0.4, fc='green',ec=\"black\")\n",
    "square3 = plt.Rectangle((-0.2,-1), 0.4, 0.4, fc='red',ec=\"black\")\n",
    "square2 = plt.Rectangle((-0.2,0), 0.4, 0.8, fc='red',ec=\"black\")\n",
    "plt.gca().add_patch(square2)\n",
    "plt.gca().add_patch(square1)\n",
    "plt.gca().add_patch(square3)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "Xgg5hhMogPXQ",
    "outputId": "b8c54575-1e46-441a-991d-9561ed668256"
   },
   "outputs": [],
   "source": [
    "# Task: plot the feature points on the robotarium grid with corresponding weights\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(weights)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "for i, w in enumerate(weights[0,1:]):\n",
    "    ax.annotate(round(w,2), (obs_points_f[0,i] + 0.02, obs_points_f[1,i] + 0.02))\n",
    "\n",
    "# Set x-axis limits\n",
    "ax.set_xlim([-1.5, 1.5])\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment the results you observe in the figure generated by the above cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDEFINING THE OLD FUNCTION:\n",
    "\n",
    "import rps.robotarium as robotarium\n",
    "from rps.utilities.transformations import *\n",
    "from rps.utilities.barrier_certificates import *\n",
    "from rps.utilities.misc import *\n",
    "from rps.utilities.controllers import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import scipy.stats as st\n",
    "import time\n",
    "import numpy as np\n",
    "# Defining the input axes\n",
    "# Note: the boundaries for the control actions are the actuation constraints imposed by the physics of the robots\n",
    "\n",
    "control_space_size = 3  # Three possible inputs for each control axis\n",
    "\n",
    "U_space_1 = np.array(np.linspace((-0.5),(0.5),control_space_size)) # Control space for the first axis\n",
    "U_space_2 = np.array(np.linspace((-0.5),(0.5),control_space_size)) # Control space for the second axis\n",
    "time_step = 0.033 # Robotarium time-step (from the documentation)\n",
    "\n",
    "\n",
    "# This function performs a \"model\" step using the documented dynamics\n",
    "# Note: from the viewpoint of the controller the dynamics is not necesarily known\n",
    "def model_step(x,velocities,time_step):\n",
    "    \"\"\"This function calculates the next pose of the robots based on the current pose, the velocities and the simulation time-step.\n",
    "    Args:\n",
    "        x : The current position of the robot. 2x1 column vector .\n",
    "        velocities : The velocities of the robot along the two control axes. 2x1 column vector. \n",
    "        time_step : simulation time-step\n",
    "    Returns:\n",
    "        The next pose of the robot as a 2x1 column vector.\n",
    "    \"\"\"\n",
    "    poses = np.zeros((2,1))\n",
    "    # Update pose of the robots\n",
    "    poses[0] = x[0] + time_step*velocities[0]\n",
    "    poses[1] = x[1] + time_step*velocities[1]\n",
    "    return(poses)\n",
    "\n",
    "#Get the value of a Gaussian pf at a given point x, with mean u and covariance covar\n",
    "def my_logpdf(x, u, covar):\n",
    "    \"\"\"This function calculates the value of a multivariate Gaussian pdf at a given point x, with mean u and covariance covar\n",
    "\n",
    "    Args:\n",
    "        x : The point at which the pdf is evaluated. Nx1 column vector.\n",
    "        u : The mean vector of the Gaussian distribution. Nx1 column vector.\n",
    "        covar : The covariance matrix of the Gaussian distribution. NxN matrix.\n",
    "\n",
    "    Returns:\n",
    "        The value of the Gaussian pdf at x.\n",
    "    \"\"\"\n",
    "    k = len(x)  # dimension\n",
    "    a = np.transpose(x - u)\n",
    "    b = np.linalg.inv(covar)\n",
    "    c = x - u\n",
    "    d = np.matmul(a, b)\n",
    "    e = np.matmul(d, c)\n",
    "    numer = np.exp(-0.5 * e)\n",
    "    f = (2 * np.pi)**k\n",
    "    g = np.linalg.det(covar)\n",
    "    denom = np.sqrt(f * g)\n",
    "    pdf = numer / denom\n",
    "    return pdf\n",
    "\n",
    "\n",
    "##### WP0: formalize the control problem #####\n",
    "\n",
    "# Task: reverse engineer the cost function used by the robots. What is the problem formulation? \n",
    "#      Is the one below a good cost for the task? Create a heatmap to visualize the cost \n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "##### WP1: fill-in the code for the function below.\n",
    "#         The function needs to return the optimal action sampled from the optimal policy.\n",
    "#         The action is used in the simulation loop #####\n",
    "\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points, cost_func):\n",
    "    ###\n",
    "    # Perform a control step given the fact that the target pf is uniform.\n",
    "    # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "    \n",
    "    target_pf = 1/control_space_size**2 # Uniform pf q(u_k|x_k-1)\n",
    "    time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size)) #Initialize pf\n",
    "    for i in range(control_space_size):\n",
    "        for j in range(control_space_size):\n",
    "            # Task: what do the next three lines do?\n",
    "            \"\"\"\n",
    "            The next three lines calculate the probability function of the next state x_k given the current state x_{k-1} and the action u_k.\n",
    "            The probability function is a multivariate Gaussian distribution with mean vector x_k = x_{k-1} + u_k * time_step and covariance matrix cov = [[0.001, 0.0002], [0.0002, 0.001]].\n",
    "            \"\"\"\n",
    "            next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov) #p(x_k|u_k,x_k-1)\n",
    "            # Task: what do the next two lines do?\n",
    "            \"\"\"\n",
    "            The next two lines extract 20 samples from the probability function p(x_k|u_k,x_k-1) calculated before.\n",
    "            \"\"\"\n",
    "            N_samples = 20\n",
    "            next_sample = f.rvs(N_samples) \n",
    "\n",
    "            # Task: what do the next three lines do?\n",
    "            \"\"\"\n",
    "            The next three lines calculate an expectation of the cost function as a mean of the cost function evaluated on the 20 samples extracted before.\n",
    "            This is done to estimate the value of the cost function in the next state.\n",
    "            According to the law of large numbers, the more samples we extract, the more accurate the estimation will be.\n",
    "            \"\"\"\n",
    "            # Calcola una stima del valore atteso del costo nello stato successivo rispetto alla funzione f(x_k|x_k-1,u_k) usando 20 campioni\n",
    "            cost=0\n",
    "            #lnp = 0\n",
    "            for k in range(N_samples):\n",
    "                cost += cost_func(next_sample[k,:],goal_points,obs_points)/N_samples\n",
    "                #lnp += np.log(f.pdf(next_sample[k,:]))/N_samples\n",
    "            # Task: write here a line of code, defining the variable log_DKL that contains the exponential in the policy\n",
    "            \"\"\"\n",
    "            Here we exploit the fact that the entropy of a pf f is defined as the expectation of the negative logarithm of f.\n",
    "            \"\"\"\n",
    "            log_DKL = np.exp(f.entropy()-cost).item() #item() function is called to cast the ndarray to a scalar which avoids a warning\n",
    "            pf[i,j] = log_DKL #Calculate the DKL for each possible input, get corresponding probability\n",
    "    # Task: obtain the normalizer for the policy, call it S2\n",
    "    \"\"\"\n",
    "    The normalizer for the policy is the sum of the pf calculated on each possible input.\n",
    "    \"\"\"\n",
    "    S2 = np.sum(pf)\n",
    "    # Task: obtain the normalized pf (call the variable pf)\n",
    "    \"\"\"\n",
    "    To normalize the pf, we divide it by the normalizer S2.\n",
    "    \"\"\"\n",
    "    pf = np.divide(pf,S2)\n",
    "\n",
    "    # Adesso abbiamo p(u_k|x_{k-1}) e facciamo il sampling della prossima azione di controllo\n",
    "    # This is a trick to properly sample from the multi-dimensional pf\n",
    "    flat = pf.flatten()\n",
    "    sample_index = np.random.choice(a=flat.size, p=flat) # We sample an action from the flattened pf\n",
    "    # Take this index and adjust it so it matches the original array\n",
    "    adjusted_index = np.unravel_index(sample_index, pf.shape) # This function converts the index of the flattened pf back into a tuple of two indices for the original action space\n",
    "\n",
    "    action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1)) # We extract the control actions on the two control axes and we reshape them into a 2x1 column vector\n",
    "\n",
    "    return(action)\n",
    "\n",
    "def robotarium_simulation(initial_conditions = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))], \n",
    "                          max_iteration=2500, show_simulation=True, cost_function=state_cost):\n",
    "    %matplotlib tk\n",
    "    # Instantiate Robotarium object\n",
    "    N = 1 #Amount of robots per simulation\n",
    "    MAX_ITERATIONS = max_iteration\n",
    "    SHOW_SIMULATIONS= show_simulation\n",
    "\n",
    "    N_experiment = len(initial_conditions)\n",
    "    # X_si is going to be two-dimensional state history\n",
    "    X_Si = [0]*N_experiment\n",
    "    # D_Xi is going to be two-dimensional inputs history\n",
    "    D_Xi = [0]*N_experiment\n",
    "\n",
    "    # This first for loop creates the initial conditions\n",
    "    for I in range(N_experiment):\n",
    "\n",
    "        X_si = []\n",
    "        D_xi = []\n",
    "\n",
    "        r = robotarium.Robotarium(number_of_robots=N, show_figure=SHOW_SIMULATIONS, initial_conditions=np.copy(initial_conditions[I]), sim_in_real_time=False)\n",
    "\n",
    "        # Create mapping from the control inputs to the actual velocity commands to the unicycle\n",
    "        # Note: this is a very practical situation (robots often provide transformation functions to low level commands)\n",
    "        si_to_uni_dyn = create_si_to_uni_dynamics_with_backwards_motion() #Converts single integrator inputs to unicycle inputs (low-level controller)\n",
    "        _, uni_to_si_states = create_si_to_uni_mapping()\n",
    "        \n",
    "        # define x initially\n",
    "        x = r.get_poses()\n",
    "        x_si = uni_to_si_states(x)\n",
    "\n",
    "        # Plotting Parameters\n",
    "        CM = np.random.rand(N+10,3) # Random Colors\n",
    "        goal_marker_size_m = 0.15\n",
    "        obs_marker_size_m = 0.15\n",
    "        marker_size_goal = determine_marker_size(r,goal_marker_size_m)\n",
    "        marker_size_obs = determine_marker_size(r,obs_marker_size_m)\n",
    "        font_size = determine_font_size(r,0.1)\n",
    "        line_width = 5\n",
    "\n",
    "        # Create Goal Point Markers\n",
    "        #Text with goal identification\n",
    "        goal_caption = ['G{0}'.format(ii) for ii in range(goal_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        goal_points_text = [r.axes.text(goal_points[0,ii], goal_points[1,ii], goal_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "        goal_markers = [r.axes.scatter(goal_points[0,ii], goal_points[1,ii], s=marker_size_goal, marker='s', facecolors='none',edgecolors=CM[ii,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(goal_points.shape[1])]\n",
    "\n",
    "        #Text with goal identification\n",
    "        obs_caption = ['OBS{0}'.format(ii) for ii in range(obs_points.shape[1])]\n",
    "        #Plot text for caption\n",
    "        obs_points_text = [r.axes.text(obs_points[0,ii], obs_points[1,ii], obs_caption[ii], fontsize=font_size, color='k',fontweight='bold',horizontalalignment='center',verticalalignment='center',zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "        obs_markers = [r.axes.scatter(obs_points[0,ii], obs_points[1,ii], s=marker_size_obs, marker='s', facecolors='none',edgecolors=CM[ii+1,:],linewidth=line_width,zorder=-2)\n",
    "        for ii in range(obs_points.shape[1])]\n",
    "\n",
    "        r.step()\n",
    "\n",
    "        i = 0\n",
    "        # While the robot is away from the objective ...\n",
    "        while (np.size(at_pose(np.vstack((x_si,x[2,:])), goal_points, position_error=0.15,rotation_error=100)) != N and i < MAX_ITERATIONS ):\n",
    "\n",
    "            # Get poses of agents\n",
    "            x = r.get_poses()\n",
    "            x_si = uni_to_si_states(x)\n",
    "\n",
    "            #Add to the dataset\n",
    "            X_si.append(x_si)\n",
    "\n",
    "            # The lines below define the pdf of the robot \n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            x_pdf = st.multivariate_normal(x_si.reshape((2,)),cov)\n",
    "            x_sample = x_pdf.rvs() #Noisy state\n",
    "\n",
    "            # This is about plotting\n",
    "            for j in range(goal_points.shape[1]):\n",
    "                goal_markers[j].set_sizes([determine_marker_size(r, goal_marker_size_m)])\n",
    "\n",
    "            for j in range(obs_points.shape[1]):\n",
    "                obs_markers[j].set_sizes([determine_marker_size(r, obs_marker_size_m)])\n",
    "\n",
    "            # Task: compute the action from the policy. Call the variable dxi: \n",
    "            # this is the action sampled from the optimal solution to the control problem\n",
    "            dxi = Control_step(x_sample, U_space_1, U_space_2, goal_points, obs_points, cost_function)\n",
    "            D_xi.append(dxi)\n",
    "\n",
    "            # Transform single integrator velocity commands to unicycle inputs (low level controller)\n",
    "            dxu = si_to_uni_dyn(dxi, x)\n",
    "\n",
    "            # Set the velocities inputs\n",
    "            r.set_velocities(np.arange(N), dxu)\n",
    "            # Iterate the simulation\n",
    "            r.step()\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        if i >= MAX_ITERATIONS:\n",
    "            print(\"SIMULATION {} FAILED!\".format(I))\n",
    "        \n",
    "        D_Xi[I] = D_xi\n",
    "        X_Si[I] = X_si\n",
    "\n",
    "        #Call at end of script to print debug information and for your script to run on the Robotarium server properly\n",
    "        r.call_at_scripts_end()\n",
    "        plt.close()\n",
    "        \n",
    "    return X_Si, D_Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altertive cost functions\n",
    "def state_cost_without_borders(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "def state_cost_with_additional_term(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "    state_cost = ((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) -1/((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2 +0.1)\n",
    "    cost = 30*state_cost + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "def indicator_function(X,Y):\n",
    "    \"\"\" x > o < di una certa quantità e y > o < di una certa quantità \"\"\"\n",
    "    condition = np.logical_or(np.logical_or(X < -1.5, X > 1.5), np.logical_or(Y < -1.0, Y > 1.0))\n",
    "    inf = 500\n",
    "    result = np.where(condition, inf, 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def my_cilinder(x,u):\n",
    "    r = 0.4\n",
    "    k = 1000\n",
    "    height = 100\n",
    "    \n",
    "    temp = height*(-1/(1+np.exp(-k*((x[0]-u[0])**2+(x[1]-u[1])**2-(r**2)))) + 1)\n",
    "    return temp\n",
    "\n",
    "def state_cost_cone_for_goal_point_cilinder_for_obstacles(state,goal_points,obs_points):\n",
    "\n",
    "    value = 0.05\n",
    "    a = 0.5\n",
    "    b = 0.5\n",
    "\n",
    "    v = np.array([value, value], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        \n",
    "        gauss_sum += my_cilinder(state[:2],obs_points[:2,i])\n",
    "\n",
    "    \n",
    "    if np.abs(state[0]-goal_points[0]) < 2 or np.abs(state[1]-goal_points[1]) < 2:\n",
    "        goal_point_cost = np.sqrt((state[0]-goal_points[0])**2/(a**2) + (state[1]-goal_points[1])**2/(b**2))\n",
    "    else:\n",
    "        goal_point_cost = (state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2\n",
    "    \n",
    "    cost = 30*goal_point_cost + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/value)**2)/(value*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/value)**2)/(value*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/value)**2)/(value*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/value)**2)/(value*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "def state_cost_higher_goal_weight(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 60*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "def state_cost_bigger_border(state,goal_points,obs_points):\n",
    "    displacement = 0.20\n",
    "    dev_std_border=0.08\n",
    "    multiplier_factor=dev_std_border/0.02\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(\n",
    "                multiplier_factor* np.exp(-0.5*((state[0]-(-1.5 -displacement ))/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi))\n",
    "                + multiplier_factor* np.exp(-0.5*((state[0]-1.5 - displacement)/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi)) \n",
    "                + multiplier_factor* np.exp(-0.5*((state[1]-1.0 -displacement)/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi))\n",
    "                + multiplier_factor* np.exp(-0.5*((state[1]-(-1.0 -displacement))/dev_std_border)**2)/(dev_std_border*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "dropwave = lambda X,Y,f,s,p,o,k,A, obstacle: A*(o + np.cos(f*np.sqrt(((X-obstacle[0])/k)**2+((Y-obstacle[1])/k)**2))/((s)*((X-obstacle[0])**2+(Y-obstacle[1])**2)+p))\n",
    "dropwave_attenuation = lambda X,Y,f,s,p,o,k,A,goal,obstacle,alpha,beta: dropwave(X,Y,f,s,p,o,k,A, obstacle) * np.exp(alpha*np.sqrt((X-goal[0])**2+(Y-goal[1])**2)) * np.exp(-beta*np.sqrt((X-obstacle[0])**2+(Y-obstacle[1])**2))\n",
    "\n",
    "def experimental(state, goal_points, obs_points, parameters=None):\n",
    "    if parameters is None:\n",
    "        f =  57.67374\n",
    "        s =  100.0001\n",
    "        p =  30.000100000000003\n",
    "        o =  0.0\n",
    "        k =  4.185\n",
    "        A =  21.035\n",
    "        alpha =  4.54734\n",
    "        beta =  5.917910000000001\n",
    "    else:\n",
    "        f = parameters['f']\n",
    "        s = parameters['s']\n",
    "        p = parameters['p']\n",
    "        o = parameters['o']\n",
    "        k = parameters['k']\n",
    "        A = parameters['A']\n",
    "        alpha = parameters['alpha']\n",
    "        beta = parameters['beta']\n",
    "    \n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar) + dropwave_attenuation(state[0],state[1],f,s,p,o,k,A,goal_points,obs_points[:2,i],alpha,beta)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "exp_distance = lambda X,Y,Lambda: np.exp(Lambda*np.sqrt(X**2+Y**2))\n",
    "single_wave = lambda X,Y,goal, A, k,omega,Lambda, alpha: A*(exp_distance(X,Y,Lambda)/k**2+np.sin(omega*exp_distance(X,Y,Lambda)/k**2))*np.exp(-(exp_distance(X,Y,Lambda)/k**2)**2) * np.exp(alpha*np.sqrt((X-goal[0])**2+(Y-goal[1])**2))\n",
    "\n",
    "euclidean_distance = lambda X,Y,O=np.array([0,0]): np.sqrt((X-O[0])**2+(Y-O[1])**2)\n",
    "manhattan_distance = lambda X,Y,O=np.array([0,0]): np.maximum(np.abs(X-O[0]),np.abs(Y-O[1]))\n",
    "vector_module = lambda X,Y: np.sqrt(X**2+Y**2)\n",
    "gaussian = lambda X, mu, sigma: np.exp(-0.5*((X-mu)/sigma)**2)/(sigma*np.sqrt(2*np.pi))\n",
    "theta = lambda X,Y,G,O: np.arccos(((X-G[0])*(O[0]-G[0]) + (Y-G[1])*(O[1]-G[1]))/(vector_module(X-G[0],Y-G[1])+0.00001)/(vector_module(O[0]-G[0],O[1]-G[1])+0.00001))\n",
    "#decay = lambda X,Y,G,O,l: np.exp(-l*(theta(X,Y,G,O)/np.pi)**2)\n",
    "decay = lambda X,Y,G,O,l: theta(X,Y,G,O)<l*np.pi/100\n",
    "circular_barrier = lambda X,Y,center,r,sigma,A,obstacle,l: A*gaussian(euclidean_distance(X,Y,center),r+manhattan_distance(obstacle[0],obstacle[1],center),sigma)*decay(X,Y,center,obstacle,l)\n",
    "\n",
    "def single_wave_cost(state, goal_points, obs_points, parameters=None):\n",
    "    if parameters is None:\n",
    "        r = 0.266390\n",
    "        sigma = 0.226100\n",
    "        A = 27.200140\n",
    "        l = 0.000000\n",
    "    else:\n",
    "        r = parameters['r']\n",
    "        sigma = parameters['sigma']\n",
    "        A = parameters['A']\n",
    "        l= parameters['l']\n",
    "    \n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += circular_barrier(state[0],state[1],goal_points,r,sigma,A,obs_points[:2,i],l) #+ 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum + 10*(np.exp(-0.5*((state[0]-(-1.5))/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/0.02)**2)/(0.02*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/0.02)**2)/(0.02*np.sqrt(2*np.pi)))\n",
    "    return(cost)\n",
    "\n",
    "experimental_cost_generator = lambda params: lambda state, goal_points, obs_points: experimental(state, goal_points, obs_points, params)\n",
    "single_wave_cost_generator = lambda params: lambda state, goal_points, obs_points: single_wave_cost(state, goal_points, obs_points, params)\n",
    "\n",
    "\n",
    "def my_cost(state, goal_points, obs_points,params):\n",
    "\n",
    "    rho = params['rho']\n",
    "    var_x = params['var_x']\n",
    "    var_y = params['var_y']\n",
    "    A = params['A']\n",
    "\n",
    "    barrier_variance = 0.05\n",
    "    cov = np.array([[var_x, rho*np.sqrt(var_x)*np.sqrt(var_y)], [rho*np.sqrt(var_x)*np.sqrt(var_y), var_y]])\n",
    "\n",
    "    goal_cost = (state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2 -1/np.sqrt(((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2 +0.1))\n",
    "\n",
    "    obstacle_cost = 0\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        obstacle_cost += A*my_logpdf(state[:2],obs_points[:2,i],cov) + 5*my_logpdf(state[:2],obs_points[:2,i],np.array([[0.008, 0], [0, 0.008]]))\n",
    "    \n",
    "\n",
    "\n",
    "    barrier_cost = 10*(np.exp(-0.5*((state[0]-(-1.5))/barrier_variance)**2)/(barrier_variance*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[0]-1.5)/barrier_variance)**2)/(barrier_variance*np.sqrt(2*np.pi)) + np.exp(-0.5*((state[1]-1.0)/barrier_variance)**2)/(barrier_variance*np.sqrt(2*np.pi))\n",
    "                + np.exp(-0.5*((state[1]-(-1.0))/barrier_variance)**2)/(barrier_variance*np.sqrt(2*np.pi))) + indicator_function(state[0],state[1])\n",
    "\n",
    "\n",
    "\n",
    "    return (30*goal_cost + obstacle_cost + barrier_cost)\n",
    "\n",
    "def my_cost_generator(params):\n",
    "    return lambda state, goal_points, obs_points: my_cost(state, goal_points, obs_points, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_parameters = {\n",
    "    'baseline':{\n",
    "        'f': 57.67374,\n",
    "        's': 100.0001,\n",
    "        'p': 30.000100000000003,\n",
    "        'o': 0.0,\n",
    "        'k': 4.185,\n",
    "        'A': 21.035,\n",
    "        'alpha': 4.54734,\n",
    "        'beta': 5.917910000000001,\n",
    "    },\n",
    "    'test':{\n",
    "        'r': 0.266390,\n",
    "        'sigma': 0.226100,\n",
    "        'A': 27.200140,\n",
    "    },\n",
    "    'test2':{\n",
    "        'r': 0.564660,\n",
    "        'sigma': 0.089060,\n",
    "        'A': 4.627710,\n",
    "    },\n",
    "    'test3':{\n",
    "        'r': 0.161600,\n",
    "        'sigma': 0.140310,\n",
    "        'A': 38.486350,\n",
    "        'l': 4.645100,\n",
    "    },\n",
    "    'bivariate':{\n",
    "        'rho': 0.000000,\n",
    "        'var_x': 0.140000,\n",
    "        'var_y': 0.140000,\n",
    "        'A': 30.000000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_CONDITIONS_BASELINE = [np.array(np.mat('1.4;0.9; 0')),np.array(np.mat('0.2;0.9; 0')),np.array(np.mat('1.2;-0.5; 0')),np.array(np.mat('-1;0.9; 0'))]\n",
    "GOAL_POINTS_BASELINE = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "OBS_POINTS_BASELINE = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "COST_FUNCTION_BASELINE = state_cost\n",
    "\n",
    "SCENARIOS = {\n",
    "    'baseline': {\n",
    "        'initial_conditions': INITIAL_CONDITIONS_BASELINE,\n",
    "        'goal_points': GOAL_POINTS_BASELINE,\n",
    "        'obs_points': OBS_POINTS_BASELINE\n",
    "    },\n",
    "    'six-robots-towards-walls': {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('1.4;0.9; 0')),\n",
    "            np.array(np.mat('0.3;0.9; 1.57')),\n",
    "            np.array(np.mat('1.2;-0.5; 0')),\n",
    "            np.array(np.mat('-0.3;0.9; 1.57')),\n",
    "            np.array(np.mat('-1.40;0.625; 3.14')),\n",
    "            np.array(np.mat('0.5;-0.9; -1.57'))],\n",
    "        'goal_points': GOAL_POINTS_BASELINE,\n",
    "        'obs_points': OBS_POINTS_BASELINE\n",
    "    },\n",
    "    'obstacles-ahead-goal': {\n",
    "        'initial_conditions': [np.array(np.mat('1.4;0.9; 0')),\n",
    "                               np.array(np.mat('0.2;0.9; 0')),\n",
    "                               np.array(np.mat('1.2;-0.8; 0')),\n",
    "                               np.array(np.mat('-1;0.9; 0')),\n",
    "                               np.array(np.mat('-1;-0.75; 0')),\n",
    "                               np.array(np.mat('-1.2;-0.15; 0')),\n",
    "                               np.array(np.mat('0.4;-0.8; 0')),\n",
    "                               np.array(np.mat('-1.2;0.4; 0'))],\n",
    "        'goal_points': np.array(np.mat('+1.3; -0.3; 0')),\n",
    "        'obs_points': np.array(np.mat('0.5 -0.8 -0.6 0.7 0.8; -0.5 0.4 -0.8 0.8 -0.8; 0 0 0 0 0'))\n",
    "    },\n",
    "    'robot-on-walls': {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('1.47; 0.2; 0')),\n",
    "            np.array(np.mat('1.47; 0.2; 1.57')),\n",
    "            np.array(np.mat('1.47; 0.2; 3.14')),\n",
    "            np.array(np.mat('1.47; 0.2; -1.57'))],\n",
    "        'goal_points': np.array(np.mat('-1.3; 0; 0')),\n",
    "        'obs_points': np.array(np.mat('0.0 0.0 0.0; -0.8 0.8 0; 0 0 0 '))\n",
    "    },\n",
    "    'three-obstacles-wall':  {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('-1.0; 0.0; 0'))\n",
    "        ],\n",
    "        'goal_points': np.array(np.mat('1.0; 0.0; 0')),\n",
    "        'obs_points': np.array(np.mat('0.0 0.0 0.0; 0.0 -0.3 0.3; 0 0 0 '))\n",
    "    },\n",
    "    'single-obstacle-wall':  {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('-1.0; 0.0; 0'))\n",
    "        ],\n",
    "        'goal_points': np.array(np.mat('1.0; 0.0; 0')),\n",
    "        'obs_points': np.array(np.mat('0.0; 0.0; 0.0'))\n",
    "    },\n",
    "    'five-obstacles-wall':  {\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('-1.0; 0.0; 0'))\n",
    "        ],\n",
    "        'goal_points': np.array(np.mat('1.0; 0.0; 0')),\n",
    "        'obs_points': np.array(np.mat('0.0 0.0 0.0 0.0 0.0;0.6 0.3 0.0 -0.3 -0.6; 0 0 0 0 0'))\n",
    "    },\n",
    "    'obastacles_issue': {\n",
    "        'initial_conditions': [np.array(np.mat('-1.4;0.9; 0')),\n",
    "                               np.array(np.mat('-1.4;0; 0')),\n",
    "                               np.array(np.mat('0;0.9; 0')),\n",
    "                               np.array(np.mat('1.4;0.9; 0')),\n",
    "                               np.array(np.mat('1.4;0; 0'))\n",
    "                               ],\n",
    "        'goal_points': np.array(np.mat('0; 0; 0')),\n",
    "        'obs_points': np.array(np.mat('-0.3 -0.3 -0.3 0 0.3 0.3 0.3; -0.3 0 0.3 0.3 0.3 0 -0.3; 0 0 0 0 0 0 0'))\n",
    "    },\n",
    "    'goal_up_left': {\n",
    "        'initial_conditions': INITIAL_CONDITIONS_BASELINE,\n",
    "        'goal_points': np.array(np.mat('-1.4; 0.8; 0')),\n",
    "        'obs_points': OBS_POINTS_BASELINE\n",
    "    },\n",
    "    'for_ioc':{\n",
    "        'initial_conditions': [\n",
    "            np.array(np.mat('-0.3;-0.65; 0')),\n",
    "            np.array(np.mat('-0.3;0.9; 1.57')),\n",
    "            np.array(np.mat('-1.40;0.625; 3.14')),\n",
    "            np.array(np.mat('1.4;0.9; 0')),\n",
    "            np.array(np.mat('0.2;0.9; 0')),\n",
    "            np.array(np.mat('1.2;-0.8; 0')),\n",
    "            np.array(np.mat('-1;0.9; 0')),\n",
    "            np.array(np.mat('-1;-0.75; 0')),\n",
    "            np.array(np.mat('-1.4;-0.15; 0')),\n",
    "            np.array(np.mat('-1.4;-0.45; 0')),\n",
    "            np.array(np.mat('-1.4;-0.85; 0')),\n",
    "            np.array(np.mat('-1.4; 0.90; 0')),\n",
    "            np.array(np.mat('-1.4;-0.90; 0')),\n",
    "            np.array(np.mat('0.4;-0.8; 0')), #non arriva\n",
    "            np.array(np.mat('-1.47; 0.0; 0')),\n",
    "            np.array(np.mat('-1.47; 0.0; 3.14')),\n",
    "            np.array(np.mat('-1.47;-0.25; 3.14')),\n",
    "            np.array(np.mat('-1.47; 0.25; 3.14'))],\n",
    "        'goal_points': np.array(np.mat('+1.3; -0.3; 0')),\n",
    "        'obs_points': np.array(np.mat('0.5 -0.8 -0.5 0.7 0.8; -0.5 0.4 -0.8 0.8 -0.8; 0 0 0 0 0'))\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "selected_scenario = 'for_ioc'\n",
    "selected_cost_function = state_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define goal and obstacle points\n",
    "goal_points = SCENARIOS[selected_scenario]['goal_points']\n",
    "obs_points = SCENARIOS[selected_scenario]['obs_points'] # (3 x n_obstacles) matrix. Each column represents an obstacle. Rows contain the (x,y,theta) of the obstacle.\n",
    "\n",
    "# Dopo vedremo che questi 'ostacoli' virtuali si mappano a due ostacoli fisici, uno centrato in (0, -0.8) e un altro più lungo centrato in (0, 0.5).\n",
    "\n",
    "# Define the initial states of the robots\n",
    "initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']\n",
    "\n",
    "# Define the cost function\n",
    "state_cost = selected_cost_function\n",
    "\n",
    "# Define whether to show the robotarium simulations\n",
    "SHOW_SIMULATIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid boundaries\n",
    "X_LIMITS = [-1.5, 1.5]\n",
    "Y_LIMITS = [-1, 1]\n",
    "EPSILON_LIMITS = 0 # Used to plot a little bit outside the robotarium boundaries\n",
    "X_SIZE = X_LIMITS[1]-X_LIMITS[0]+2*EPSILON_LIMITS\n",
    "Y_SIZE = Y_LIMITS[1]-Y_LIMITS[0]+2*EPSILON_LIMITS\n",
    "\n",
    "# Define the grid of points where to evaluate the cost function\n",
    "X_axis = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "Y_axis = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "\n",
    "X_grid, Y_grid = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "# Evaluate the cost function on the grid\n",
    "costs = np.array([[state_cost((x,y),goal_points,obs_points) for x in X_axis] for y in Y_axis] ) #TODO: speed up this line by vectorizing it\n",
    "costs = costs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Plot the cost function\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_xlabel('X [m]', labelpad=10)\n",
    "ax.set_ylabel('Y [m]', labelpad=10)\n",
    "ax.set_title('Cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "surf = ax.plot_surface(X_grid, Y_grid, costs, cmap=cm.coolwarm, linewidth=0, antialiased=False, ccount=100, rcount=100) #rcount and ccount are used to make the surface smoother\n",
    "fig.colorbar(surf, shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_grid, Y_grid, costs, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "# Plot the level curves of the cost function\n",
    "contour = ax.contour(X_grid, Y_grid, costs, cmap='coolwarm', levels=10, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=0, vmax=600) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "# Scatter the obstacle points\n",
    "ax.scatter(obs_points[0,:], obs_points[1,:], marker='o', s=50, color='red', zorder=3)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax) \n",
    "\n",
    "# Create a rectangle\n",
    "rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "# Add the rectangle to the plot\n",
    "ax.add_patch(rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Calculate the gradient of the cost function\n",
    "X_grad, Y_grad = np.gradient(costs.T, X_axis, Y_axis) #We need to transpose the costs matrix because we are passing the x axis as the first argument\n",
    "# Calculate the module of the gradient\n",
    "Z_grad = np.sqrt(X_grad**2 + Y_grad**2).T #We need to transpose the result because we need to plot it\n",
    "\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xlabel('X [m]', labelpad=20)\n",
    "ax.set_ylabel('Y [m]', labelpad=20)\n",
    "ax.set_title('Cost function gradient module', fontdict={'fontsize': 20})\n",
    "\n",
    "# Plot the heatmap of the module of the gradient of the cost function\n",
    "pcolormesh = ax.pcolormesh(X_grid, Y_grid, Z_grad, zorder=1, cmap='RdGy', vmin=0, vmax=200)\n",
    "\n",
    "# Add a colorbar\n",
    "fig.colorbar(pcolormesh, ax=ax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "initial_conditions = np.array(initial_conditions).squeeze()\n",
    "if initial_conditions.ndim == 1:\n",
    "    initial_conditions = initial_conditions.reshape((1,3))\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot()\n",
    "ax.scatter(initial_conditions[:,0],initial_conditions[:,1])\n",
    "ax.scatter(goal_points[0],goal_points[1], color='green')\n",
    "ax.scatter(obs_points[0,:], obs_points[1,:], marker='o', s=50, color='red', zorder=3)\n",
    "ax.set_xlim(X_LIMITS)\n",
    "ax.set_ylim(Y_LIMITS)\n",
    "l = 0.1\n",
    "for state_index, state in enumerate(initial_conditions):\n",
    "    ax.arrow(state[0],state[1],l*np.cos(state[2]),l*np.sin(state[2]))\n",
    "    ax.annotate(str(state_index),(state[0],state[1]))\n",
    "\n",
    "# Restore the initial_conditions variable to the original value\n",
    "initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = SCENARIOS[selected_scenario]['initial_conditions']\n",
    "N_experiment = len(initial_conditions)\n",
    "X_Si, D_Xi = robotarium_simulation(initial_conditions=initial_conditions, max_iteration=2500, show_simulation=True, cost_function=state_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X_Si #Insieme degli stati nel sistema single-integrator (y_1, y_2) per ogni simulazione\n",
    "UU = D_Xi #Insieme delle azioni di controllo per ogni simulazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for plotting\n",
    "X = []\n",
    "X_plot = []\n",
    "U = []\n",
    "U_plot = []\n",
    "\n",
    "for i in range(len(XX)):\n",
    "    X.append(np.array(XX[i])) #X=XX ma è un array di array numpy\n",
    "    X_plot.append(np.array(XX[i])) #X_plot = XX ma è un array numpy\n",
    "X = np.concatenate(X, axis=0) #X adesso è un array numpy. La prima dimensione contiene le traiettorie di tutti gli esperimenti concatenate e la secoda indicizza lo stato\n",
    "print(X.shape)\n",
    "X = np.reshape(X, (-1, 2)) # Rimuove l'ultima dimensione inutile\n",
    "U = []\n",
    "for i in range(len(UU)):\n",
    "    U.append(np.array(UU[i])) #U=UU ma è un array di array numpy\n",
    "    U_plot.append(np.array(UU[i])) #U_plot=UU ma è un array di array numpy\n",
    "\n",
    "U = np.concatenate(U, axis=0) #Stessa cosa di prima per le traiettorie di ingresso\n",
    "U = np.reshape(U, (-1, 2))\n",
    "\n",
    "simulation_from_FOC=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Task: plot trajectories with different colors\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.plot(trajectory[:,0],trajectory[:,1])\n",
    "\n",
    "#Add a star to the starting point of each trajectory\n",
    "for I in range(N_experiment):\n",
    "    trajectory = np.array(X_Si[I])\n",
    "    plt.scatter(trajectory[0,0], trajectory[0,1], marker='*', s=200, color='black', zorder=3)\n",
    "\n",
    "#Add a legend to the plot\n",
    "legend = []\n",
    "for i in range(N_experiment):\n",
    "    legend = legend + ['Experiment {}'.format(i+1)]\n",
    "    plt.legend(legend)\n",
    "\n",
    "#Draw obstacles\n",
    "for i in range(len(obs_points[0])):\n",
    "    for j in range(len(obs_points[1])):\n",
    "        if (i==j):\n",
    "            square=plt.Rectangle((obs_points[0][i]-0.15,obs_points[1][j]-0.15), 0.3, 0.3, fc='red',ec=\"black\")\n",
    "            plt.gca().add_patch(square)\n",
    "\n",
    "#Draw goal point\n",
    "square = plt.Rectangle((float(goal_points[0][0])-0.15,float(goal_points[1][0])-0.15), 0.3, 0.3, fc='green',ec=\"black\") # Obiettivo da raggiungere\n",
    "plt.gca().add_patch(square)\n",
    "\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.xlabel('X [m]')\n",
    "plt.ylabel('Y [m]')\n",
    "plt.savefig('Training_Trajectories.jpg',dpi=1000,bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_feature(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32) #vettore delle varianze\n",
    "    covar = np.diag(v) #matrice di varianze e covarianze\n",
    "    features = np.zeros(len(obs_points[0]) + 1)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar) #Modelliamo gli ostacoli come multivariate gaussiane indipendenti (cov=0) centrate nell'ostacolo ipotizzato\n",
    "\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) #La prima feature è relativa al raggiungimento del goal point\n",
    "\n",
    "    return features\n",
    "\n",
    "def augmented_feature_walls(next_state,goal_points,obs_points,N_feature):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32) #vettore delle varianze\n",
    "    covar = np.diag(v) #matrice di varianze e covarianze\n",
    "    features = np.zeros(len(obs_points[0]) + 1)\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        features[i+1] = my_logpdf(next_state[:2],obs_points[:2,i],covar) #Modelliamo gli ostacoli come multivariate gaussiane indipendenti (cov=0) centrate nell'ostacolo ipotizzato\n",
    "    features[0] = (((next_state[0]-goal_points[0])**2 + (next_state[1]-goal_points[1])**2)) #La prima feature è relativa al raggiungimento del goal point\n",
    "    \n",
    "    x_walls = np.linspace(X_LIMITS[0], X_LIMITS[1], 5)\n",
    "    y_walls = np.linspace(Y_LIMITS[0], Y_LIMITS[1], 5)\n",
    "    \n",
    "    x_wall = lambda x: np.exp(-0.5*((next_state[0]-x)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "    y_wall = lambda y: np.exp(-0.5*((next_state[1]-y)/0.02)**2)/(0.02*np.sqrt(2*np.pi)) \n",
    "    \n",
    "    for x in x_walls:\n",
    "        features = np.append(features,x_wall(x))\n",
    "        \n",
    "    for y in y_walls:\n",
    "        features = np.append(features,y_wall(y))\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FEATURES= {\n",
    "    'baseline': {\n",
    "        'obs_points_f': np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')),\n",
    "        'N_feature': 16,\n",
    "        'func': base_feature\n",
    "    },\n",
    "    'augmented_feature_walls': {\n",
    "        'obs_points_f': np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8;-0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0')),\n",
    "        'N_feature': 26,\n",
    "        'func': augmented_feature_walls\n",
    "    },\n",
    "    'augmented_feature_point': {\n",
    "        'obs_points_f': np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8 1.2 1.2 1.2 1.2 1.2 0.4 0.4 0.4 0.4 0.4 -0.4 -0.4 -0.4 -0.4 -0.4 -1.2 -1.2 -1.2 -1.2 -1.2; -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8; 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ')),\n",
    "        'N_feature': 36,\n",
    "        'func': base_feature\n",
    "    },\n",
    "    'augmented_feature_point_walls': {\n",
    "        'obs_points_f': np.array(np.mat('0 0 0 0 0 0.8 0.8 0.8 0.8 0.8 -0.8 -0.8 -0.8 -0.8 -0.8 1.2 1.2 1.2 1.2 1.2 0.4 0.4 0.4 0.4 0.4 -0.4 -0.4 -0.4 -0.4 -0.4 -1.2 -1.2 -1.2 -1.2 -1.2; -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8 -0.8 -0.4 0 0.4 0.8; 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ')),\n",
    "        'N_feature': 46,\n",
    "        'func': augmented_feature_walls\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "INITIAL_CONDITIONS_BASELINE_IOC = [np.array(np.mat('-1.4;0.9; 0')),np.array(np.mat('1;0.9; 0')),np.array(np.mat('1;-0.25; 0'))]\n",
    "GOAL_POINTS_BASELINE_IOC = np.array(np.mat('-1.4; -0.8; 0'))\n",
    "OBS_POINTS_BASELINE_IOC = np.array(np.mat('0 0 0 0 0;0.2 0.4 0.6 0.8 -0.8;0 0 0 0 0'))\n",
    "\n",
    "SCENARIOS_IOC = {\n",
    "    'baseline': {\n",
    "        'initial_conditions': INITIAL_CONDITIONS_BASELINE_IOC,\n",
    "        'goal_points': GOAL_POINTS_BASELINE_IOC,\n",
    "        'obs_points': OBS_POINTS_BASELINE_IOC\n",
    "    },\n",
    "    'more-point': {\n",
    "        'initial_conditions': [np.array(np.mat('-0.6;-0.75; 0')),np.array(np.mat('-0.1;-0.7; -1.57')), np.array(np.mat('-1.2; 0.4; 0'))],\n",
    "        'goal_points': np.array(np.mat('+1.3; -0.3; 0')),\n",
    "        'obs_points': np.array(np.mat('0.5 -0.8 -0.5 0.7 0.8; -0.5 0.4 -0.8 0.8 -0.8; 0 0 0 0 0'))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#REDEFINING THE OLD FUNCTION:\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import CenteredNorm\n",
    "from scipy import interpolate\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "def plt_featurt_point(obs_points_f):\n",
    "    %matplotlib inline\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red')\n",
    "    ax.scatter(goal_points[0,:],goal_points[1,:], color='green')\n",
    "    ax.set_ylim(-1,1)\n",
    "    ax.set_xlim(-1.5,1.5)\n",
    "    ax.set_xlabel('X [m]')\n",
    "    ax.set_ylabel('Y [m]')\n",
    "    ax.set_title('Feature points', fontdict={'fontsize': 20})\n",
    "\n",
    "def plt_feature_function_part(goal_points,obs_points_f,N_feature,feature):\n",
    "    %matplotlib inline\n",
    "\n",
    "    # Define the grid of points where to evaluate the feature function\n",
    "    X_axis = np.linspace(X_LIMITS[0]-EPSILON_LIMITS, X_LIMITS[1]+EPSILON_LIMITS, 300)\n",
    "    Y_axis = np.linspace(Y_LIMITS[0]-EPSILON_LIMITS, Y_LIMITS[1]+EPSILON_LIMITS, 200)\n",
    "    X_grid, Y_grid = np.meshgrid(X_axis, Y_axis)\n",
    "\n",
    "    # Calculate the feature function on the grid\n",
    "    features_array = np.array([[feature((x,y),goal_points,obs_points_f,N_feature) for x in X_axis] for y in Y_axis] ) #TODO: speed up this line by vectorizing it\n",
    "\n",
    "\n",
    "    # Plot the feature functions for the obstacles\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.set_xlabel('X [m]')\n",
    "    ax.set_ylabel('Y [m]')\n",
    "    ax.set_title('Feature functions (obstacles)', fontdict={'fontsize': 20})\n",
    "    ax.set_xlim(X_LIMITS[0],X_LIMITS[1])\n",
    "    ax.set_ylim(Y_LIMITS[0],Y_LIMITS[1])\n",
    "\n",
    "    ax.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red', zorder=3)\n",
    "\n",
    "\n",
    "    Z = np.sum(features_array[:,:,1:], axis=-1)\n",
    "    colormesh = ax.pcolormesh(X_grid, Y_grid, Z, shading='auto', zorder=1)\n",
    "    ax.contour(X_grid, Y_grid, Z, cmap='coolwarm', levels=5, linewidths=2, linestyles='dashed', alpha=1, zorder=2) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "    # Plot feature function for the goal\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.set_xlabel('X [m]')\n",
    "    ax.set_ylabel('Y [m]')\n",
    "    ax.set_title('Feature functions (goal)', fontdict={'fontsize': 20})\n",
    "    ax.set_xlim(X_LIMITS[0],X_LIMITS[1])\n",
    "    ax.set_ylim(Y_LIMITS[0],Y_LIMITS[1])\n",
    "\n",
    "    ax.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "\n",
    "\n",
    "    Z = features_array[:,:,0]\n",
    "    colormesh = ax.pcolormesh(X_grid, Y_grid, Z, shading='auto', zorder=1)\n",
    "    ax.contour(X_grid, Y_grid, Z, cmap='coolwarm', levels=5, linewidths=2, linestyles='dashed', alpha=1, zorder=2) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "def solve_inverse_optimal_control(old_simulation,N_feature,obs_points_f,goal_points,U_space_1,U_space_2,control_space_size,feature):\n",
    "    X=old_simulation\n",
    "    M = np.size(X,axis=0) - 1 #size è la lunghezza di tutte le simulazioni concatenate. Concatenare le simulazioni genera 4 termini spuri.\n",
    "    w = cp.Variable((1,N_feature)) #Variabili decisionali. Sono tante quanto il numero di features.\n",
    "    constraints = [w >= 0] #Per hp del problema.\n",
    "    R = np.zeros((99,1)) #??? Mai usato\n",
    "    L = [] #Termini della funzione target da minimizzare (la funzione da minimizzare sum(L))\n",
    "\n",
    "    f_expect = np.zeros((2,20)) #???\n",
    "    feature_sampled = np.zeros((N_feature,M)) #Questo è il valore atteso a sinistra in blu (tranne la moltiplicazione per w che si può portare fuori)\n",
    "    PF = np.zeros((control_space_size,control_space_size,M)) #Questa è la funzione q soprasegnato indicizzata in (u_k, k) dove k è l'indice temporale\n",
    "\n",
    "    for i in range(M): #i è l'i-esimo termine della funzione target da ottimizzare (somma da 1 a M), sto fissando x hat \n",
    "\n",
    "        #############################################################################################################################\n",
    "        features = np.zeros((N_feature,control_space_size,control_space_size)) #Questo è il valore atteso a destra in verde (tranne la moltiplicazione per w che si può portare fuori)\n",
    "        state = np.array(X[i,:]) #Get the state \\hat x_k-1\n",
    "\n",
    "        x0 = state.reshape(-1,1) #è equivalente alla flatten(), x0 è lo stato iniziale (x0[0],x0[1])\n",
    "        time_step = 0.033\n",
    "\n",
    "\n",
    "        pf = np.zeros((control_space_size,control_space_size)) #Initialize pf \\overline q(u)\n",
    "\n",
    "        for j in range(control_space_size):\n",
    "            for k in range(control_space_size):\n",
    "                next_state = model_step(state,[U_space_1[j],U_space_2[k]],time_step)\n",
    "                cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "                f = st.multivariate_normal(next_state.reshape((2,)),cov) #p(x_k|\\hat x_k-1, u_k) valutata per \\hat x_k-1 e u_k fissati\n",
    "                #next_sample = f.mean #next_sample = next_state, inutile\n",
    "\n",
    "                N_samples = 5\n",
    "                next_samples = f.rvs(N_samples) #5 campioni relativi al prossimo stato. Dimensione 5 campioni x 2 variabili di stato\n",
    "                feature_sample = np.zeros((N_feature,N_samples)) # 16 feature x 5 campioni\n",
    "\n",
    "                for m in range(N_samples):\n",
    "                    feature_sample[:,m] = feature(next_samples[m,:],goal_points,obs_points_f,N_feature) #feature_sample è una matrice che tiene sulle colonne le valutazioni delle features sui campioni. Le colonne rorrispondono ai campioni.\n",
    "\n",
    "                features[:,j,k] = np.mean(feature_sample,axis=1) #la media è fatta su tutti gli elementi della riga [i,;], ovvero per ogni feature i-esima faccio la media su tutti i campioni\n",
    "                #Alla fine del ciclo features contiene la stima del valore atteso delle features per ogni possibile ingresso (j,k) con \\hat x_k-1 fissato\n",
    "                #quindi ho tutte le stime dei valori attesi a destra in verde nell'equazione. Fatta con la legge dei grandi numeri.\n",
    "                #Calculate the DKL for each possible input, get corresponding probability\n",
    "                log_DKL = np.exp(-(-f.entropy())) #Prima parte del valore atteso a destra\n",
    "                pf[j,k] = log_DKL\n",
    "        PF[:,:,i] = pf #Prima parte del valore atteso a destra per ogni valore di ingresso e u_k e stato x_k-1\n",
    "\n",
    "        features = np.reshape(features,(N_feature,control_space_size**2)) # Adesso features ha come primo indice la feature e il secondo va da 0 a 8 e indica l'ingresso di controllo\n",
    "\n",
    "        f_sampled = model_step(state,U[i+1,:],time_step) # Costuiramo la pdf p(x_k|\\hat x_k-1,\\hat u_k) che serve a calcolare il valore atteso a sinistra in blu\n",
    "        cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "        f1 = st.multivariate_normal(f_sampled.reshape((2,)),cov) #p(x_k|\\hat x_k-1,\\hat u_k)\n",
    "        next_samples_f1 = f1.rvs(N_samples) #stessa cosa di prima, stima con legge dei grandi numeri del expectation blu a sinistra\n",
    "        feature_sample_f1 = np.zeros((N_feature,N_samples))\n",
    "        for n in range(N_samples):\n",
    "            feature_sample_f1[:,n] = feature(next_samples_f1[n,:],goal_points,obs_points_f,N_feature)\n",
    "\n",
    "        feature_sampled[:,i] = np.mean(feature_sample_f1,axis=1)  # features_sampled è la stessa cosa di features fatta sul valore atteso blu. nota che u è fissata qunidi non ho come indici j e k. Ho i come indice ed è inutile.\n",
    "\n",
    "        # Task: solve, using cvx the convex optimization problem we saw in class. To do so:\n",
    "        # (i) prepare each individual term of the summation, say l;\n",
    "        # (ii) sum all the elements to define the cost function\n",
    "        # (iii) solve the problem\n",
    "        PF2 = np.reshape(PF,(-1,M))\n",
    "        # log_sum_exp prende in ingresso il vettore colonna degli elmenti da sommare\n",
    "        l = -(w @ feature_sampled[:,i]) + cp.log_sum_exp(cp.reshape(w@features[:,:],(control_space_size**2,)) + cp.log(PF2[:,i])) #(i)\n",
    "        L.append(l) #(ii)\n",
    "\n",
    "    objective = cp.Minimize(cp.sum(L)) #(iii)\n",
    "\n",
    "    prob = cp.Problem(objective)\n",
    "\n",
    "    result = prob.solve(verbose = True)\n",
    "\n",
    "    weights = w.value\n",
    "    \n",
    "    return weights,result,prob\n",
    "\n",
    "def state_cost(state,goal_points,obs_points):\n",
    "    v = np.array([0.02, 0.02], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += 20*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = 30*((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "def state_cost_estimated(state,goal_points,obs_points,weights):\n",
    "    v = np.array([0.025, 0.025], dtype=np.float32)\n",
    "    covar = np.diag(v)\n",
    "\n",
    "    gauss_sum = 0\n",
    "\n",
    "    for i in range(np.size(obs_points,axis=1)):\n",
    "        gauss_sum += -weights[:,i+1]*my_logpdf(state[:2],obs_points[:2,i],covar)\n",
    "\n",
    "    cost = -weights[:,0]*((((state[0]-goal_points[0])**2 + (state[1]-goal_points[1])**2))) + gauss_sum\n",
    "    return(cost)\n",
    "\n",
    "def recostruct_cost_map(goal_points,obs_points,state_cost_func,args={}):\n",
    "    Cost_Map = np.zeros((300,200))\n",
    "    X_axis = np.linspace(-1.5,1.5,300)\n",
    "    Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "    for i in range(200):\n",
    "        for j in range(300):\n",
    "\n",
    "            state = np.array([X_axis[j],Y_axis[i]])\n",
    "            Cost_Map[j,i] = state_cost_func(state,goal_points,obs_points,**args)\n",
    "    return Cost_Map,X_axis,Y_axis\n",
    "\n",
    "\n",
    "\n",
    "# def recostruct_cost_map_estimated(goal_points,obs_points,obs_points_f,weights):\n",
    "#     Cost_Map = np.zeros((300,200))\n",
    "#     X_axis = np.linspace(-1.5,1.5,300)\n",
    "#     Y_axis = np.linspace(-1,1,200)\n",
    "\n",
    "#     for i in range(200):\n",
    "#         for j in range(300):\n",
    "\n",
    "#             state = np.array ([X_axis[j],Y_axis[i]])\n",
    "#             Cost_Map[j,i] = state_cost_estimated(state,goal_points,obs_points_f,weights)\n",
    "#     return Cost_Map,X_axis,Y_axis\n",
    "\n",
    "# def heat_map_estimated_cost(Cost_Map,X_axis,Y_axis):\n",
    "#     %matplotlib inline\n",
    "\n",
    "#     # Transpose the data array to rotate the heatmap\n",
    "#     data_rotated = np.transpose(Cost_Map) \n",
    "    \n",
    "#     fig = plt.figure(figsize=(13,10))\n",
    "#     ax = fig.add_subplot()\n",
    "#     ax.set_xlabel('X [m]', labelpad=20)\n",
    "#     ax.set_ylabel('Y [m]', labelpad=20)\n",
    "#     ax.set_title('Estimated cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "#     # Plot the heatmap of the cost function\n",
    "#     pcolormesh = ax.pcolormesh(X_axis, Y_axis, data_rotated, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "#     # Plot the level curves of the cost function\n",
    "#     contour = ax.contour(X_axis, Y_axis, data_rotated, cmap='coolwarm', shading='linear', levels=7, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=40, vmax=100) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "#     # Add a colorbar\n",
    "#     fig.colorbar(pcolormesh, ax=ax)\n",
    "\n",
    "#     # Create a rectangle\n",
    "#     rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "#     # Add the rectangle to the plot\n",
    "#     ax.add_patch(rectangle)\n",
    "    \n",
    "#     plt.scatter(obs_points_f[0,:],obs_points_f[1,:], color='red', zorder=3)\n",
    "#     plt.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "def heat_map_cost(cost,X_axis,Y_axis,X_LIMITS,Y_LIMITS):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    fig = plt.figure(figsize=(13,10))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_xlabel('X [m]', labelpad=20)\n",
    "    ax.set_ylabel('Y [m]', labelpad=20)\n",
    "    ax.set_title('Estimated cost function', fontdict={'fontsize': 20})\n",
    "\n",
    "    # Plot the heatmap of the cost function\n",
    "    pcolormesh = ax.pcolormesh(X_axis, Y_axis, cost, cmap='coolwarm', shading='auto', zorder=1)\n",
    "\n",
    "    # Plot the level curves of the cost function\n",
    "    contour = ax.contour(X_axis, Y_axis, cost, cmap='coolwarm', shading='linear', levels=7, linewidths=2, linestyles='dashed', zorder=2, alpha=1, vmin=40, vmax=100) #vmin and vmax are used to make the contour lines more visible\n",
    "\n",
    "    # Add a colorbar\n",
    "    fig.colorbar(pcolormesh, ax=ax)\n",
    "\n",
    "    # Create a rectangle\n",
    "    rectangle = Rectangle((X_LIMITS[0], Y_LIMITS[0]), X_LIMITS[1]-X_LIMITS[0], Y_LIMITS[1]-Y_LIMITS[0], fill=False, color=\"black\", linewidth=1, zorder=3)\n",
    "    # Add the rectangle to the plot\n",
    "    ax.add_patch(rectangle)\n",
    "    return plt\n",
    "\n",
    "def add_goal_obs_heatmpap_cost(plt, obs_points, goal_points):\n",
    "    plt.scatter(obs_points[0,:],obs_points[1,:], color='red', zorder=3)\n",
    "    plt.scatter(goal_points[0,:],goal_points[1,:], color='green', zorder=3)\n",
    "    return plt\n",
    "\n",
    "def plot_3d_cost(cost,X_axis,Y_axis):\n",
    "\n",
    "    fig = plt.figure(figsize=(13,13))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_xlabel('X [m]', labelpad=10)\n",
    "    ax.set_ylabel('Y [m]', labelpad=10)\n",
    "    ax.set_zlabel('Cost')\n",
    "    ax.set_title('Estimated Cost Function', fontdict={'fontsize': 20})\n",
    "\n",
    "    surf = ax.plot_surface(X_grid, Y_grid, cost, cmap=cm.coolwarm, linewidth=0, antialiased=False, ccount=100, rcount=100) #rcount and ccount are used to make the surface smoother\n",
    "    fig.colorbar(surf, shrink=0.5)\n",
    "    plt.show()\n",
    "\n",
    "def calculate_interpolated_cost(X_LIMITS,Y_LIMITS,goal_points,obs_points_f,weights):\n",
    "    X_axis_interpolation = np.linspace(X_LIMITS[0]-0.5, X_LIMITS[1]+0.5, 600)\n",
    "    Y_axis_interpolation = np.linspace(Y_LIMITS[0]-0.5, Y_LIMITS[1]+0.5, 400)\n",
    "    X_grid_interpolation, Y_grid_interpolation = np.meshgrid(X_axis_interpolation, Y_axis_interpolation)\n",
    "    Z = np.zeros((600,400))\n",
    "    for i in range(600):\n",
    "        for j in range(400):\n",
    "            Z[i,j] = state_cost_estimated(np.array([X_axis_interpolation[i],Y_axis_interpolation[j]]),goal_points,obs_points_f,weights)\n",
    "\n",
    "\n",
    "    interpolated_cost = interpolate.LinearNDInterpolator(np.stack((X_grid_interpolation.flatten(),Y_grid_interpolation.flatten()),axis=1),Z.T.flatten())\n",
    "    return interpolated_cost ,X_axis_interpolation, Y_axis_interpolation,X_grid_interpolation, Y_grid_interpolation\n",
    "\n",
    "def plt_interpolated_cost(interpolated_cost ,X_axis_interpolation, Y_axis_interpolation,X_grid_interpolation, Y_grid_interpolation):\n",
    "    fig = plt.figure(figsize=(13,10))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_xlabel('X [m]', labelpad=20)\n",
    "    ax.set_ylabel('Y [m]', labelpad=20)\n",
    "    ax.set_title('Interpolated cost function', fontdict={'fontsize': 20})\n",
    "    TEST = np.zeros((600,400))\n",
    "\n",
    "    for i in range(600):\n",
    "        for j in range(400):\n",
    "            TEST[i,j] = interpolated_cost(X_axis_interpolation[i], Y_axis_interpolation[j])\n",
    "    pcolormesh = ax.pcolormesh(X_grid_interpolation, Y_grid_interpolation, TEST.T, cmap='coolwarm',  zorder=1)\n",
    "\n",
    "#redifne control state for ioc with interpolated cost\n",
    "def Control_step(state,U_space_1,U_space_2,goal_points,obs_points,cost_func):\n",
    "    ###\n",
    "    # Perform a control step given the fact that the target pf is uniform.\n",
    "    # The function first gets the target pf (uniform) and then applies the control solution we saw in class\n",
    "    \n",
    "    target_pf = 1/control_space_size**2 # Uniform pf q(u_k|x_k-1)\n",
    "    time_step = 0.033 # The Robotarium time-step\n",
    "\n",
    "    pf = np.zeros((control_space_size,control_space_size))\n",
    "    for i in range(control_space_size):\n",
    "        for j in range(control_space_size):\n",
    "            next_state = model_step(state,[U_space_1[i],U_space_2[j]],time_step)\n",
    "            cov = np.array([[0.001, 0.0002], [0.0002, 0.001]])\n",
    "            f = st.multivariate_normal(next_state.reshape((2,)),cov)\n",
    "            N_samples = 20\n",
    "            next_sample = f.rvs(N_samples) \n",
    "\n",
    "            # Task: what do the next three lines do?\n",
    "            # Calcola una stima del valore atteso del costo nello stato successivo rispetto alla funzione f(x_k|x_k-1,u_k) usando 20 campioni\n",
    "            cost=0\n",
    "            for k in range(N_samples):\n",
    "                #cost += state_cost_estimated(next_sample[k,:],goal_points,obs_points_f,weights)/N_samples\n",
    "                cost += cost_func(next_sample[k,:])/N_samples\n",
    "            log_DKL = np.exp(f.entropy()-cost).item() #item is used to convert the result to a scalar\n",
    "            pf[i,j] = log_DKL \n",
    "    # Task: obtain the normalizer for the policy, call it S2\n",
    "    S2 = np.sum(pf)\n",
    "    # Task: obtain the normalized pf (call the variable pf)\n",
    "    pf = np.divide(pf,S2)\n",
    "\n",
    "    # Adesso abbiamo p(u_k|x_{k-1}) e facciamo il sampling della prossima azione di controllo\n",
    "    # This is a trick to properly sample from the multi-dimensional pf\n",
    "    flat = pf.flatten()\n",
    "    sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "    # Take this index and adjust it so it matches the original array\n",
    "    adjusted_index = np.unravel_index(sample_index, pf.shape) #Indice dell'azione\n",
    "\n",
    "    #Formatta l'azione come vettore colonna\n",
    "    action = np.reshape(np.array([U_space_1[adjusted_index[0]],U_space_2[adjusted_index[1]]]),(2,1))\n",
    "    return(action)\n",
    "\n",
    "def manipulation_simulation_data(X_Si, D_Xi):\n",
    "    XX = X_Si\n",
    "    UU = D_Xi\n",
    "    X = []\n",
    "    X_plot = []\n",
    "    U = []\n",
    "    U_plot = []\n",
    "\n",
    "    for i in range(len(XX)):\n",
    "        X.append(np.array(XX[i]))\n",
    "        X_plot.append(np.array(XX[i]))\n",
    "\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    X = np.reshape(X, (-1, 2))\n",
    "\n",
    "    U = []\n",
    "    for i in range(len(UU)):\n",
    "        U.append(np.array(UU[i]))\n",
    "        U_plot.append(np.array(UU[i]))\n",
    "\n",
    "    U = np.concatenate(U, axis=0)\n",
    "    U = np.reshape(U, (-1, 2))\n",
    "    return X,U\n",
    "\n",
    "def plot_trajectory(X_Si, N_experiment, obs_points, goal_points):\n",
    "    %matplotlib inline\n",
    "    #Task: plot trajectories with different colors\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    for I in range(N_experiment):\n",
    "        trajectory = np.array(X_Si[I])\n",
    "        plt.plot(trajectory[:,0],trajectory[:,1])\n",
    "\n",
    "    # Add a star to the starting point of each trajectory\n",
    "    for I in range(N_experiment):\n",
    "        trajectory = np.array(X_Si[I])\n",
    "        plt.scatter(trajectory[0,0], trajectory[0,1], marker='*', s=200, color='black')\n",
    "\n",
    "    # Add a legend to the plot\n",
    "    legend = []\n",
    "    for i in range(N_experiment):\n",
    "        legend = legend + ['Experiment {}'.format(i+1)]\n",
    "        plt.legend(legend)\n",
    "\n",
    "\n",
    "    #Draw obstacles\n",
    "    for i in range(len(obs_points[0])):\n",
    "        for j in range(len(obs_points[1])):\n",
    "            if (i==j):\n",
    "                square=plt.Rectangle((obs_points[0][i]-0.15,obs_points[1][j]-0.15), 0.3, 0.3, fc='red',ec=\"black\")\n",
    "                plt.gca().add_patch(square)\n",
    "\n",
    "    #Draw goal point\n",
    "    square = plt.Rectangle((float(goal_points[0][0])-0.15,float(goal_points[1][0])-0.15), 0.3, 0.3, fc='green',ec=\"black\") # Obiettivo da raggiungere\n",
    "    plt.gca().add_patch(square)\n",
    "\n",
    "    #plt.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.xlabel('X [m]')\n",
    "    plt.ylabel('Y [m]')\n",
    "    #plt.show()\n",
    "    return plt\n",
    "\n",
    "def add_feature_plot_trajectory(plt, obs_points_f):\n",
    "    plt.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "    return plt\n",
    "\n",
    "def plt_feature_point_weight(weights, obs_points_f):\n",
    "    %matplotlib inline\n",
    "\n",
    "    print(weights)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(obs_points_f[0,:],obs_points_f[1,:])\n",
    "    for i, w in enumerate(weights[0,1:]):\n",
    "        ax.annotate(round(w,2), (obs_points_f[0,i] + 0.02, obs_points_f[1,i] + 0.02))\n",
    "\n",
    "    # Set x-axis limits\n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "\n",
    "    # Set y-axis limits\n",
    "    ax.set_ylim([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ioc_problem(selected_feature,selected_scenario_ioc):\n",
    "    feature = FEATURES[selected_feature]['func']\n",
    "    obs_points_f = FEATURES[selected_feature]['obs_points_f']\n",
    "    N_feature = FEATURES[selected_feature]['N_feature'] \n",
    "    print(\"feature\", feature)\n",
    "    goal_points = SCENARIOS_IOC[selected_scenario_ioc]['goal_points']\n",
    "    obs_points = SCENARIOS_IOC[selected_scenario_ioc]['obs_points'] # (3 x n_obstacles) matrix. Each column represents an obstacle. Rows contain the (x,y,theta) of the obstacle.\n",
    "    initial_conditions = SCENARIOS_IOC[selected_scenario_ioc]['initial_conditions']\n",
    "\n",
    "    plt_featurt_point(obs_points_f)\n",
    "    plt_feature_function_part(goal_points,obs_points_f,N_feature,feature)\n",
    "    weights,result,prob= solve_inverse_optimal_control(simulation_from_FOC,N_feature,obs_points_f,goal_points,U_space_1,U_space_2,control_space_size,feature)\n",
    "\n",
    "    \n",
    "    Cost_Map_original,X_axis_original,Y_axis_original = recostruct_cost_map(goal_points,obs_points, state_cost)\n",
    "    Cost_Map,X_axis,Y_axis=recostruct_cost_map(goal_points,obs_points_f, state_cost_estimated, {\"weights\": weights})\n",
    "    plt=heat_map_cost(np.transpose(Cost_Map),X_axis,Y_axis,X_LIMITS,Y_LIMITS)\n",
    "    add_goal_obs_heatmpap_cost(plt, obs_points_f, goal_points)\n",
    "    #plt_3d_estimated_cost(Cost_Map,X_axis,Y_axis)\n",
    "    plot_3d_cost(np.transpose(Cost_Map) ,X_axis,Y_axis)\n",
    "    interpolated_cost ,X_axis_interpolation, Y_axis_interpolation,X_grid_interpolation, Y_grid_interpolation = calculate_interpolated_cost(X_LIMITS,Y_LIMITS,goal_points,obs_points_f,weights)\n",
    "    plt_interpolated_cost(interpolated_cost ,X_axis_interpolation, Y_axis_interpolation,X_grid_interpolation, Y_grid_interpolation)\n",
    "    N_experiment = len(initial_conditions)\n",
    "    X_Si, D_Xi= robotarium_simulation(initial_conditions=initial_conditions, max_iteration=25000, show_simulation=True, cost_function=interpolated_cost)\n",
    "    X,U= manipulation_simulation_data(X_Si, D_Xi)\n",
    "    plt=plot_trajectory(X_Si, N_experiment, obs_points, goal_points)\n",
    "    add_feature_plot_trajectory(plt, obs_points_f)\n",
    "    plt_feature_point_weight(weights, obs_points_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 'baseline'\n",
    "selected_scenario_ioc = 'more-point'\n",
    "solve_ioc_problem(selected_feature,selected_scenario_ioc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding feature point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 'augmented_feature_point'\n",
    "selected_scenario_ioc = 'more-point'\n",
    "solve_ioc_problem(selected_feature,selected_scenario_ioc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thickening of the featur point grid, allows us to more accurately reconstruct the cost associated with obstacles that are not in exact correspondence with a featur point.\n",
    "This improvement cannot be taken to the extreme, as the optimization problem would grow out of control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding boundiers term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 'augmented_feature_walls'\n",
    "selected_scenario_ioc = 'more-point'\n",
    "solve_ioc_problem(selected_feature,selected_scenario_ioc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted by the previous case, the thickening of feature points allows for more accurate construction of obstacles in the robotarium, but not for reconstructing walls.\n",
    "Therefore, additional features are exhibited in which using univariate Gaussians arranged uniformly in the robotarium, we try to reconstruct just the walls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding feature point and boundiers term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = 'augmented_feature_point_walls'\n",
    "selected_scenario_ioc = 'more-point'\n",
    "solve_ioc_problem(selected_feature,selected_scenario_ioc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the two previous improvements were combined so that both problems that emerged previously were solved"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ddc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
